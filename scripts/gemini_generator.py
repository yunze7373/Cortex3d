#!/usr/bin/env python3
"""
Gemini å¤šè§†è§’å›¾åƒç”Ÿæˆå™¨
ä½¿ç”¨ Gemini API ç”Ÿæˆå››è§†å›¾è§’è‰²è®¾è®¡å›¾

ä½¿ç”¨å…±äº«é…ç½®: ä» config.py å¯¼å…¥æç¤ºè¯æ¨¡æ¿å’Œæ¨¡å‹åç§°

ä¾èµ–:
    pip install google-generativeai pillow
"""

import argparse
import os
import sys
from pathlib import Path
from datetime import datetime
from typing import Optional
import base64
import io

# å¯¼å…¥å…±äº«é…ç½®
from config import IMAGE_MODEL, build_multiview_prompt

# Lazy imports
genai = None
PIL_Image = None
cv2 = None
np = None


def _ensure_imports():
    """å»¶è¿Ÿå¯¼å…¥ä¾èµ–åº“"""
    global genai, PIL_Image, cv2, np
    
    if genai is None:
        try:
            import google.generativeai as _genai
            from PIL import Image as _Image
            from google.generativeai.types import HarmCategory, HarmBlockThreshold
            genai = _genai
            PIL_Image = _Image
        except ImportError as e:
            raise ImportError(
                f"ç¼ºå°‘å¿…è¦ä¾èµ–: {e}\n"
                "è¯·è¿è¡Œ: pip install google-generativeai pillow"
            )
    
    # å¯é€‰çš„ OpenCV å¯¼å…¥ï¼ˆç”¨äºå›¾åƒå¤„ç†ï¼‰
    if cv2 is None:
        try:
            import cv2 as _cv2
            import numpy as _np
            cv2 = _cv2
            np = _np
        except ImportError:
            pass  # å¦‚æœæ²¡æœ‰ opencvï¼ŒæŸäº›åŠŸèƒ½ä¼šè¢«ç¦ç”¨


# ä½¿ç”¨å…±äº«é…ç½®ä¸­çš„é»˜è®¤æ¨¡å‹ï¼ˆå’Œä»£ç†æ¨¡å¼å®Œå…¨ä¸€è‡´ï¼‰
DEFAULT_MODEL = IMAGE_MODEL  # models/nano-banana-pro-preview


# =============================================================================
# Gemini API è°ƒç”¨
# =============================================================================

def generate_character_views(
    character_description: str,
    api_key: str,
    model_name: str = DEFAULT_MODEL,
    output_dir: str = "test_images",
    auto_cut: bool = True,
    style: str = "cinematic character",
    view_mode: str = "4-view",
    custom_views: list = None,
    negative_prompt: str = None,
    reference_image_path: str = None,
    use_strict_mode: bool = False,
    resolution: str = "2K",
    original_args = None,
    export_prompt: bool = False,
    subject_only: bool = False,
    with_props: list = None
) -> Optional[str]:
    """
    ä½¿ç”¨ Gemini API ç”Ÿæˆå¤šè§†å›¾è§’è‰²å›¾åƒ
    
    Args:
        character_description: è§’è‰²æè¿°
        api_key: Gemini API Key
        model_name: æ¨¡å‹åç§°
        output_dir: è¾“å‡ºç›®å½•
        auto_cut: æ˜¯å¦è‡ªåŠ¨åˆ‡å‰²
        style: é£æ ¼æè¿°
        view_mode: è§†è§’æ¨¡å¼ (4-view, 6-view, 8-view, custom)
        custom_views: è‡ªå®šä¹‰è§†è§’åˆ—è¡¨
        negative_prompt: è´Ÿé¢æç¤ºè¯
        reference_image_path: å‚è€ƒå›¾åƒè·¯å¾„ï¼ˆç”¨äºå›¾ç”Ÿå›¾ï¼‰
        use_strict_mode: ä¸¥æ ¼å¤åˆ¶æ¨¡å¼ï¼ˆåŸºäºå‚è€ƒå›¾åƒï¼‰
        resolution: ç›®æ ‡åˆ†è¾¨ç‡ (1K/2K/4K)ï¼Œé€šè¿‡åå¤„ç†å®ç°
        subject_only: åªå¤„ç†ä¸»ä½“ï¼Œç§»é™¤èƒŒæ™¯ç‰©ä½“
        with_props: è¦åŒ…å«çš„é“å…·åˆ—è¡¨
    
    Returns:
        ç”Ÿæˆçš„å›¾ç‰‡è·¯å¾„
    """
    _ensure_imports()
    
    # é…ç½® API
    genai.configure(api_key=api_key)
    
    print("="*60)
    print("Gemini å¤šè§†è§’å›¾åƒç”Ÿæˆå™¨ (ç›´è¿æ¨¡å¼)")
    print("="*60)
    print(f"[æ¨¡å‹] {model_name}")
    print(f"[è§’è‰²æè¿°] {character_description[:100]}...")
    print(f"[é£æ ¼] {style}")
    print(f"[è§†è§’æ¨¡å¼] {view_mode}")
    if reference_image_path:
        mode_label = "ä¸¥æ ¼å¤åˆ¶" if use_strict_mode else "å‚è€ƒå›¾åƒ"
        print(f"[{mode_label}] {reference_image_path}")
    if subject_only:
        print(f"[ä¸»ä½“éš”ç¦»] åªå¤„ç†ä¸»ä½“äººç‰©ï¼Œç§»é™¤èƒŒæ™¯ç‰©ä½“")
    if with_props:
        print(f"[åŒ…å«é“å…·] {', '.join(with_props)}")
    print(f"[åˆ†è¾¨ç‡] {resolution}")
    print("-"*60)
    
    # å¤„ç†å‚è€ƒå›¾åƒï¼ˆè½¬ä¸º base64ï¼‰
    reference_image_b64 = None
    if reference_image_path:
        try:
            with open(reference_image_path, 'rb') as f:
                image_bytes = f.read()
            reference_image_b64 = base64.b64encode(image_bytes).decode('utf-8')
            # è·å– MIME ç±»å‹
            if reference_image_path.lower().endswith('.png'):
                mime = 'image/png'
            elif reference_image_path.lower().endswith(('.jpg', '.jpeg')):
                mime = 'image/jpeg'
            else:
                mime = 'image/png'
            reference_image_b64 = f"data:{mime};base64,{reference_image_b64}"
            print(f"[INFO] å‚è€ƒå›¾åƒå·²åŠ è½½")
        except Exception as e:
            print(f"[WARNING] æ— æ³•åŠ è½½å‚è€ƒå›¾åƒ: {e}")
            reference_image_b64 = None
    
    # æ„å»ºæç¤ºè¯ï¼ˆå’Œä»£ç†æ¨¡å¼å®Œå…¨ä¸€è‡´ï¼‰
    if use_strict_mode and reference_image_b64:
        from config import build_strict_copy_prompt
        full_prompt = build_strict_copy_prompt(
            view_mode=view_mode,
            custom_views=custom_views,
            style=style,
            subject_only=subject_only,
            with_props=with_props
        )
        print("[æ¨¡å¼] ä¸¥æ ¼å¤åˆ¶ - 100% åŸºäºå‚è€ƒå›¾åƒ")
    elif reference_image_b64:
        from config import build_image_reference_prompt
        full_prompt = build_image_reference_prompt(
            character_description or "Extract character details and generate multi-view",
            view_mode=view_mode,
            custom_views=custom_views,
            style=style,
            subject_only=subject_only,
            with_props=with_props
        )
        print(f"[æ¨¡å¼] å›¾åƒå‚è€ƒ - æå–ç‰¹å¾ç”Ÿæˆ {view_mode if view_mode != 'custom' else str(custom_views)} è§†è§’")
    else:
        full_prompt = build_multiview_prompt(
            character_description, 
            style=style,
            view_mode=view_mode,
            custom_views=custom_views,
            subject_only=subject_only,
            with_props=with_props
        )
    
    # æ·»åŠ è´Ÿé¢æç¤ºè¯
    if negative_prompt:
        print(f"[è´Ÿé¢æç¤ºè¯] {negative_prompt[:60]}...")
    
    print("[INFO] æ­£åœ¨ç”Ÿæˆå›¾åƒ... (å¯èƒ½éœ€è¦ 30-60 ç§’)")
    
    try:
        # å‡†å¤‡ API è°ƒç”¨å‚æ•°ï¼ˆå’Œä»£ç†æ¨¡å¼å®Œå…¨å¯¹é½ï¼‰
        from google.generativeai.types import HarmCategory, HarmBlockThreshold
        
        # åˆ†è¾¨ç‡æ˜ å°„
        resolution_map = {
            "1K": "1K",
            "2K": "2K",
            "4K": "4K"
        }
        image_size = resolution_map.get(resolution, "2K")
        
        # å®½é«˜æ¯”ï¼ˆé»˜è®¤ 3:2 é€‚åˆå››è§†å›¾æ¨ªæ’ï¼‰
        aspect_ratio = "3:2"
        
        # æ„å»ºç”Ÿæˆé…ç½®
        generation_config = {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
        }
        
        # å®‰å…¨è®¾ç½®ï¼ˆå’Œä»£ç†ä¸€è‡´ï¼‰
        safety_settings = [
            {"category": HarmCategory.HARM_CATEGORY_HARASSMENT, "threshold": HarmBlockThreshold.BLOCK_ONLY_HIGH},
            {"category": HarmCategory.HARM_CATEGORY_HATE_SPEECH, "threshold": HarmBlockThreshold.BLOCK_ONLY_HIGH},
            {"category": HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, "threshold": HarmBlockThreshold.BLOCK_ONLY_HIGH},
            {"category": HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, "threshold": HarmBlockThreshold.BLOCK_ONLY_HIGH},
        ]
        
        # å®šä¹‰å›é€€æ¨¡å‹ï¼ˆå’Œä»£ç†æ¨¡å¼å®Œå…¨ä¸€è‡´ï¼‰
        FALLBACK_MODELS = {
            "models/nano-banana-pro-preview": "gemini-2.5-flash-image",
            "nano-banana-pro-preview": "gemini-2.5-flash-image",
        }
        
        current_model = model_name
        MAX_RETRIES = 1
        
        for attempt in range(MAX_RETRIES + 1):
            print(f"[Gemini API] å°è¯•æ¨¡å‹: {current_model} (å°è¯• {attempt+1}/{MAX_RETRIES+1})")
            
            # åˆ›å»ºæ¨¡å‹
            model = genai.GenerativeModel(current_model)
        
            # åˆ›å»ºæ¨¡å‹
            model = genai.GenerativeModel(current_model)
        
            # å‡†å¤‡å†…å®¹åˆ—è¡¨
            contents = [full_prompt]
            
            # å¦‚æœæœ‰å‚è€ƒå›¾åƒï¼Œæ·»åŠ åˆ°å†…å®¹ä¸­
            if reference_image_b64:
                # è§£æ data URL
                if reference_image_b64.startswith('data:'):
                    header, b64_data = reference_image_b64.split(',', 1)
                    mime_type = header.split(';')[0].split(':')[1]
                else:
                    b64_data = reference_image_b64
                    mime_type = 'image/png'
                
                # æ·»åŠ å›¾åƒéƒ¨åˆ†
                contents.append({
                    'mime_type': mime_type,
                    'data': b64_data
                })
            
            # Gemini ä¼˜åŒ–ï¼šä½¿ç”¨è¯­ä¹‰è´Ÿé¢æç¤ºï¼ˆæ­£é¢æè¿°æ‰€éœ€åœºæ™¯ï¼‰
            # æ ¹æ® Gemini API æ–‡æ¡£å»ºè®®ï¼Œé¿å…ç›´æ¥åˆ—å‡ºç¦æ­¢é¡¹ï¼Œè€Œæ˜¯å¼ºè°ƒæ­£é¢è¦æ±‚
            if negative_prompt:
                # å°†ä¼ ç»Ÿè´Ÿé¢æç¤ºè¯è½¬æ¢ä¸ºè¯­ä¹‰æ­£é¢æŒ‡ä»¤
                semantic_avoidance = """
## ğŸ›¡ï¸ QUALITY REQUIREMENTS (what the image MUST have):
- Clean, anatomically correct figure with proper limb count and proportions
- Consistent pose maintained identically across all panels
- Head, gaze, and body orientation frozen in the same position in every view
- All limbs in exactly the same position and crossing order across views
- High quality, sharp details, no artifacts or distortions
- Clean panel layout with consistent sizing
- No text, labels, or overlays on the image"""
                contents[0] += semantic_avoidance
            
            # ===================================================================
            # å¯¼å‡ºæç¤ºè¯æ¨¡å¼ï¼šè¾“å‡ºå‚æ•°è€Œä¸è°ƒç”¨ API
            # ===================================================================
            if export_prompt:
                print("\n" + "="*70)
                print("ğŸ“‹ å¯¼å‡ºæç¤ºè¯å’Œå‚æ•° (å¤åˆ¶åˆ° Gemini App ä½¿ç”¨)")
                print("="*70)
                
                print(f"\nã€æ¨èæ¨¡å‹ã€‘")
                print(f"   nano-banana-pro-preview (æœ€ä½³å›¾åƒç”Ÿæˆæ¨¡å‹)")
                print(f"   å¤‡ç”¨: gemini-2.5-flash-image")
                print(f"   æç¤º: åœ¨ AI Studio æˆ– API ä¸­ä½¿ç”¨ä¸Šè¿°æ¨¡å‹åç§°")
                
                print(f"\nã€é…ç½®å‚æ•°å»ºè®®ã€‘")
                print(f"   åˆ†è¾¨ç‡: {image_size}")
                print(f"   å®½é«˜æ¯”: {aspect_ratio}")
                print(f"   Temperature: {generation_config.get('temperature', 0.7)}")
                print(f"   Top P: {generation_config.get('top_p', 0.95)}")
                print(f"   Top K: {generation_config.get('top_k', 40)}")
                
                print(f"\nã€å®Œæ•´æç¤ºè¯ã€‘")
                print("-"*70)
                print(contents[0])
                print("-"*70)
                
                # æ˜¾ç¤ºè´Ÿé¢æç¤ºè¯ä¿¡æ¯ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼Œä¾›å‚è€ƒï¼‰
                if negative_prompt:
                    print(f"\nã€è´Ÿé¢æç¤ºè¯ä¿¡æ¯ã€‘")
                    print(f"   ğŸ“‹ åŸå§‹è´Ÿé¢æç¤ºè¯ (å·²è½¬æ¢ä¸ºè¯­ä¹‰æ­£é¢æŒ‡ä»¤):")
                    print(f"   {negative_prompt}")
                    print(f"   ")
                    print(f"   âœ… Gemini ä¼˜åŒ–: å·²è‡ªåŠ¨è½¬æ¢ä¸º 'QUALITY REQUIREMENTS' æ­£é¢æè¿°")
                    print(f"   ğŸ’¡ æ ¹æ® Gemini API æ–‡æ¡£å»ºè®®ï¼Œä½¿ç”¨è¯­ä¹‰è´Ÿé¢æç¤ºæ•ˆæœæ›´å¥½")
                
                if reference_image_b64:
                    print(f"\nã€âš ï¸  å‚è€ƒå›¾åƒ - é‡è¦ã€‘")
                    print(f"   æ–‡ä»¶è·¯å¾„: {reference_image_path}")
                    print(f"   å›¾åƒç±»å‹: {mime_type}")
                    print(f"   ")
                    print(f"   ğŸ“ æ“ä½œæ­¥éª¤:")
                    print(f"      1. åœ¨ Gemini App ä¸­ç‚¹å‡» ğŸ“ (é™„ä»¶) æŒ‰é’®")
                    print(f"      2. ä¸Šä¼ å›¾åƒ: {reference_image_path}")
                    print(f"      3. å›¾åƒä¼šæ˜¾ç¤ºåœ¨å¯¹è¯æ¡†ä¸­")
                    print(f"      4. ç„¶åç²˜è´´ä¸Šé¢çš„ã€å®Œæ•´æç¤ºè¯ã€‘")
                    if use_strict_mode:
                        print(f"   ")
                        print(f"   ğŸ¯ ä¸¥æ ¼æ¨¡å¼: ç”Ÿæˆçš„å›¾åƒå°† 100% åŸºäºä¸Šä¼ çš„å‚è€ƒå›¾")
                
                print(f"\nã€å®‰å…¨è®¾ç½®ã€‘")
                print(f"   éªšæ‰°: BLOCK_ONLY_HIGH")
                print(f"   ä»‡æ¨è¨€è®º: BLOCK_ONLY_HIGH")
                print(f"   æ€§æš—ç¤º: BLOCK_ONLY_HIGH")
                print(f"   å±é™©å†…å®¹: BLOCK_ONLY_HIGH")
                
                print(f"\n{'='*70}")
                print("ğŸ’¡ å®Œæ•´ä½¿ç”¨æµç¨‹:")
                print("="*70)
                print("\nç¬¬ä¸€æ­¥: æ‰“å¼€ Gemini App")
                print("   è®¿é—®: https://gemini.google.com")
                print("   æˆ–ä½¿ç”¨ Gemini ç§»åŠ¨åº”ç”¨")
                
                print("\nç¬¬äºŒæ­¥: é€‰æ‹©æ¨¡å‹")
                print("   åœ¨ AI Studio ä¸­ä½¿ç”¨: nano-banana-pro-preview")
                print("   æˆ–åœ¨ä»£ç ä¸­è°ƒç”¨: models/nano-banana-pro-preview")
                
                if reference_image_b64:
                    print("\nç¬¬ä¸‰æ­¥: ä¸Šä¼ å‚è€ƒå›¾åƒ âš ï¸ å…ˆä¸Šä¼ å›¾åƒ!")
                    print(f"   1. ç‚¹å‡»å¯¹è¯æ¡†å·¦ä¸‹è§’çš„ ğŸ“ (é™„ä»¶) å›¾æ ‡")
                    print(f"   2. é€‰æ‹©å›¾åƒæ–‡ä»¶: {reference_image_path}")
                    print(f"   3. ç­‰å¾…å›¾åƒä¸Šä¼ å¹¶æ˜¾ç¤ºåœ¨å¯¹è¯æ¡†ä¸­")
                    step_four = "ç¬¬å››æ­¥"
                else:
                    step_four = "ç¬¬ä¸‰æ­¥"
                
                print(f"\n{step_four}: ç²˜è´´æç¤ºè¯")
                print("   1. å¤åˆ¶ä¸Šé¢ã€å®Œæ•´æç¤ºè¯ã€‘éƒ¨åˆ†çš„å…¨éƒ¨å†…å®¹")
                print("   2. ç²˜è´´åˆ° Gemini å¯¹è¯æ¡†ä¸­")
                if reference_image_b64:
                    print("   3. ç¡®è®¤å›¾åƒå’Œæç¤ºè¯éƒ½å·²åœ¨å¯¹è¯æ¡†ä¸­")
                
                print(f"\nç¬¬{'äº”' if reference_image_b64 else 'å››'}æ­¥: å‘é€å¹¶ç­‰å¾…")
                print("   1. ç‚¹å‡»å‘é€æŒ‰é’®")
                print("   2. ç­‰å¾… 30-60 ç§’ç”Ÿæˆå®Œæˆ")
                print("   3. ç”Ÿæˆçš„å›¾åƒä¼šæ˜¾ç¤ºåœ¨å›å¤ä¸­")
                
                print(f"\nç¬¬{'å…­' if reference_image_b64 else 'äº”'}æ­¥: ä¿å­˜å›¾åƒ")
                print("   1. å³é”®ç‚¹å‡»ç”Ÿæˆçš„å›¾åƒ")
                print("   2. é€‰æ‹© 'ä¿å­˜å›¾ç‰‡ä¸º...'")
                print("   3. ä¿å­˜åˆ°æ‚¨çš„è¾“å‡ºç›®å½•")
                
                print("\n" + "="*70)
                print("âœ… æç¤º: å¦‚æœç”Ÿæˆå¤±è´¥,è¯·æ£€æŸ¥:")
                print("   - æ˜¯å¦é€‰æ‹©äº†æ”¯æŒå›¾åƒç”Ÿæˆçš„æ¨¡å‹")
                if reference_image_b64:
                    print("   - å‚è€ƒå›¾åƒæ˜¯å¦å·²æ­£ç¡®ä¸Šä¼ ")
                print("   - æç¤ºè¯æ˜¯å¦å®Œæ•´å¤åˆ¶(ä¸è¦é—æ¼ä»»ä½•éƒ¨åˆ†)")
                print("="*70 + "\n")
                
                # å¯¼å‡ºæ¨¡å¼ä¸‹ä¸å®é™…è°ƒç”¨ APIï¼Œç›´æ¥è¿”å›
                return None
            
            print(f"[Gemini API] è°ƒç”¨å‚æ•°: image_size={image_size}, aspect_ratio={aspect_ratio}")
            
            try:
                # è°ƒç”¨ Gemini API
                response = model.generate_content(
                    contents,
                    generation_config=generation_config,
                    safety_settings=safety_settings
                )
                
                # æ£€æŸ¥å“åº”
                if not response or not response.candidates:
                    print("[ERROR] ç”Ÿæˆå¤±è´¥: æ— è¿”å›å†…å®¹")
                    if attempt < MAX_RETRIES:
                        continue  # å°è¯•å›é€€æ¨¡å‹
                    return None
                
                # æå–å›¾åƒæ•°æ®
                image_data = None
                for part in response.candidates[0].content.parts:
                    if hasattr(part, 'inline_data') and part.inline_data:
                        if part.inline_data.mime_type.startswith('image/'):
                            image_data = part.inline_data.data
                            break
                
                if not image_data:
                    print("[ERROR] API æœªè¿”å›å›¾åƒæ•°æ®")
                    if attempt < MAX_RETRIES:
                        print(f"[INFO] å°è¯•ä½¿ç”¨å›é€€æ¨¡å‹...")
                        continue  # å°è¯•å›é€€æ¨¡å‹
                    print("[æç¤º] Gemini API å¯èƒ½ä¸æ”¯æŒè¯¥æ¨¡å‹çš„å›¾åƒç”Ÿæˆ")
                    print("       è¯·å°è¯•ä½¿ç”¨ --mode proxy é€šè¿‡ä»£ç†æœåŠ¡è®¿é—®")
                    return None
                
                # ä¿å­˜å›¾åƒ
                output_path = Path(output_dir)
                output_path.mkdir(parents=True, exist_ok=True)
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"character_{timestamp}.png"
                filepath = output_path / filename
                
                # è§£ç å¹¶ä¿å­˜
                image_bytes = base64.b64decode(image_data) if isinstance(image_data, str) else image_data
                image = PIL_Image.open(io.BytesIO(image_bytes))
                image.save(str(filepath))
                
                print(f"[ä¿å­˜] {filepath}")
                
                # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                break
                
            except Exception as e:
                error_msg = str(e)
                
                # æ£€æµ‹é…é¢é”™è¯¯ï¼ˆResourceExhausted / 429ï¼‰
                is_quota_error = (
                    "429" in error_msg or 
                    "quota" in error_msg.lower() or 
                    "ResourceExhausted" in str(type(e).__name__)
                )
                
                # æ£€æµ‹æ¨¡å‹ä¸å­˜åœ¨é”™è¯¯
                is_model_not_found = "not found" in error_msg.lower() or "404" in error_msg
                
                if is_quota_error:
                    print(f"\nâš ï¸  é…é¢é™åˆ¶")
                    print(f"   æ¨¡å‹ '{current_model}' çš„å…è´¹é…é¢å·²ç”¨å®Œ")
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦å›é€€æ¨¡å‹
                    if attempt < MAX_RETRIES:
                        fallback_model = FALLBACK_MODELS.get(current_model)
                        if fallback_model and fallback_model != current_model:
                            print(f"   â†’ è‡ªåŠ¨åˆ‡æ¢åˆ°å›é€€æ¨¡å‹: {fallback_model}")
                            current_model = fallback_model
                            continue  # é‡è¯•
                    
                    # å¦‚æœå·²ç»æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç»™å‡ºå‹å¥½æç¤º
                    print(f"\n{'='*70}")
                    print(f"ğŸ’¡ è§£å†³æ–¹æ¡ˆ - è¯·é€‰æ‹©ä»¥ä¸‹ä»»ä¸€é€‰é¡¹:")
                    print(f"{'='*70}")
                    
                    # æ„å»ºåŸºäºå®é™…å‚æ•°çš„å‘½ä»¤
                    if original_args:
                        base_cmd_parts = ["python scripts\\generate_character.py"]
                        
                        # æ·»åŠ æè¿°æˆ–å›¾åƒè¾“å…¥
                        if hasattr(original_args, 'from_image') and original_args.from_image:
                            base_cmd_parts.append(f"--from-image {original_args.from_image}")
                        elif hasattr(original_args, 'description') and original_args.description:
                            base_cmd_parts.append(f'"{original_args.description}"')
                        
                        # æ·»åŠ å…¶ä»–å‚æ•°
                        if hasattr(original_args, 'strict') and original_args.strict:
                            base_cmd_parts.append("--strict")
                        if hasattr(original_args, 'resolution') and original_args.resolution and original_args.resolution != "2K":
                            base_cmd_parts.append(f"--resolution {original_args.resolution}")
                        if hasattr(original_args, 'views') and original_args.views and original_args.views != 4:
                            base_cmd_parts.append(f"--views {original_args.views}")
                        if hasattr(original_args, 'preprocess') and original_args.preprocess:
                            base_cmd_parts.append("--preprocess")
                        
                        proxy_cmd = " ".join(base_cmd_parts + ["--mode proxy --token 'your-aiproxy-token'"])
                        direct_cmd = " ".join(base_cmd_parts + ["--mode direct --token 'another-gemini-key'"])
                        
                        print(f"\nğŸ“Œ é€‰é¡¹ 1: åˆ‡æ¢åˆ°ä»£ç†æ¨¡å¼ (æ¨è)")
                        print(f"   {proxy_cmd}")
                        
                        print(f"\nğŸ“Œ é€‰é¡¹ 2: ä½¿ç”¨ä¸åŒçš„ Gemini API Key")
                        print(f"   {direct_cmd}")
                    else:
                        # é™çº§åˆ°é€šç”¨æç¤º
                        print(f"\nğŸ“Œ é€‰é¡¹ 1: åˆ‡æ¢åˆ°ä»£ç†æ¨¡å¼ (--mode proxy --token 'your-token')")
                        print(f"ğŸ“Œ é€‰é¡¹ 2: ä½¿ç”¨ä¸åŒçš„ API Key (--mode direct --token 'new-key')")
                    
                    print(f"\nğŸ“Œ é€‰é¡¹ 3: ç­‰å¾…é…é¢æ¢å¤ (24å°æ—¶å)")
                    print(f"ğŸ“Œ é€‰é¡¹ 4: å‡çº§ä»˜è´¹è®¡åˆ’ (https://ai.google.dev/pricing)")
                    
                    print(f"\n{'='*70}")
                    print(f"ğŸ’¬ æ¨èä½¿ç”¨ä»£ç†æ¨¡å¼ä»¥è·å¾—æœ€ä½³ä½“éªŒ")
                    print(f"{'='*70}\n")
                    return None
                    
                elif is_model_not_found:
                    print(f"\nâŒ æ¨¡å‹ä¸å­˜åœ¨: {current_model}")
                    
                    if attempt < MAX_RETRIES:
                        fallback_model = FALLBACK_MODELS.get(current_model)
                        if fallback_model and fallback_model != current_model:
                            print(f"   â†’ è‡ªåŠ¨åˆ‡æ¢åˆ°å›é€€æ¨¡å‹: {fallback_model}")
                            current_model = fallback_model
                            continue  # é‡è¯•
                    
                    # æ„å»ºåŸºäºå®é™…å‚æ•°çš„ä»£ç†æ¨¡å¼å‘½ä»¤
                    if original_args:
                        base_cmd_parts = ["python scripts\\generate_character.py"]
                        if hasattr(original_args, 'from_image') and original_args.from_image:
                            base_cmd_parts.append(f"--from-image {original_args.from_image}")
                        if hasattr(original_args, 'strict') and original_args.strict:
                            base_cmd_parts.append("--strict")
                        proxy_cmd = " ".join(base_cmd_parts + ["--mode proxy --token 'your-aiproxy-token'"])
                        print(f"   ğŸ’¡ å»ºè®®ä½¿ç”¨ä»£ç†æ¨¡å¼: {proxy_cmd}")
                    else:
                        print(f"   ğŸ’¡ å»ºè®®ä½¿ç”¨ä»£ç†æ¨¡å¼ (--mode proxy --token 'your-token')")
                    return None
                    
                else:
                    # å…¶ä»–æœªçŸ¥é”™è¯¯
                    print(f"\nâŒ ç”Ÿæˆå¤±è´¥: {error_msg}")
                    
                    # å°è¯•å›é€€æ¨¡å‹
                    if attempt < MAX_RETRIES:
                        fallback_model = FALLBACK_MODELS.get(current_model)
                        if fallback_model and fallback_model != current_model:
                            print(f"   â†’ å°è¯•å›é€€æ¨¡å‹: {fallback_model}")
                            current_model = fallback_model
                            continue  # é‡è¯•
                    
                    # æœ€åä¸€æ¬¡å°è¯•ï¼Œæ‰“å°è¯¦ç»†é”™è¯¯
                    print(f"\nğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
                    import traceback
                    traceback.print_exc()
                    return None
                # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                break
                
            except Exception as e:
                error_msg = str(e)
                print(f"[ERROR] ç”Ÿæˆå¤±è´¥: {error_msg}")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦å›é€€æ¨¡å‹
                if attempt < MAX_RETRIES:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢é”™è¯¯æˆ–æ¨¡å‹ä¸æ”¯æŒé”™è¯¯
                    if "quota" in error_msg.lower() or "429" in error_msg or "not found" in error_msg.lower():
                        fallback_model = FALLBACK_MODELS.get(current_model)
                        if fallback_model and fallback_model != current_model:
                            print(f"âš ï¸  æ¨¡å‹ {current_model} è°ƒç”¨å¤±è´¥ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å›é€€æ¨¡å‹: {fallback_model}")
                            current_model = fallback_model
                            continue  # é‡è¯•
                
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œæ‰“å°è¯¦ç»†é”™è¯¯å¹¶é€€å‡º
                if attempt >= MAX_RETRIES:
                    import traceback
                    traceback.print_exc()
                    return None
        
        # å¦‚æœæˆåŠŸä¿å­˜äº†å›¾åƒï¼Œç»§ç»­å¤„ç†
            try:
                from prompts.views import get_views_by_names, get_views_for_mode
                
                # è®¡ç®—æœŸæœ›çš„è§†è„šåˆ—è¡¨
                if view_mode == "custom" and custom_views:
                    expected_view_objs = get_views_by_names(custom_views)
                else:
                    expected_view_objs = get_views_for_mode(view_mode)
                expected_views = [v.name for v in expected_view_objs]
                
                cut_and_save(str(filepath), output_dir, expected_views=expected_views)
            except Exception as e:
                print(f"[WARNING] æ— æ³•è®¡ç®—æœŸæœ›è§†è§’: {e}, ä½¿ç”¨é»˜è®¤åˆ‡å‰²")
                cut_and_save(str(filepath), output_dir)
        
        return str(filepath)
        
    except Exception as e:
        print(f"[ERROR] ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


# å·²ç§»é™¤ generate_with_imagen å’Œ generate_with_gemini_vision å‡½æ•°
# ç›´è¿æ¨¡å¼åº”è¯¥å’Œä»£ç†æ¨¡å¼ä½¿ç”¨ç›¸åŒçš„é€»è¾‘ï¼Œåªæ˜¯è®¿é—®è·¯å¾„ä¸åŒ


def cut_and_save(image_path: str, output_dir: str, expected_views: list = None):
    """
    è°ƒç”¨ image_processor åˆ‡å‰²å›¾åƒ
    """
    script_dir = Path(__file__).parent
    sys.path.insert(0, str(script_dir))
    
    try:
        from image_processor import process_quadrant_image
        
        print("\n[INFO] è‡ªåŠ¨åˆ‡å‰²å››è§†å›¾...")
        process_quadrant_image(
            input_path=image_path,
            output_dir=output_dir,
            remove_bg_flag=True,
            expected_views=expected_views,
            margin=5
        )
    except ImportError:
        print("[WARNING] æ— æ³•å¯¼å…¥ image_processorï¼Œè·³è¿‡è‡ªåŠ¨åˆ‡å‰²")
        print("[TIP] è¿è¡Œ: python scripts/image_processor.py " + image_path)
    except Exception as e:
        print(f"[WARNING] åˆ‡å‰²å¤±è´¥: {e}")


# åˆ†è¾¨ç‡æ§åˆ¶å·²åœ¨ API è°ƒç”¨æ—¶é€šè¿‡ image_size å‚æ•°æŒ‡å®š
# æ— éœ€åå¤„ç†è°ƒæ•´


def analyze_image_for_character(image_path: str, api_key: str, user_guidance: str = None, original_args = None) -> Optional[str]:
    """
    ä½¿ç”¨ Gemini åˆ†æå›¾ç‰‡ï¼Œæå–è§’è‰²ç‰¹å¾æè¿°
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        api_key: Gemini API Key
        user_guidance: ç”¨æˆ·æŒ‡å¯¼ï¼ˆå¯é€‰ï¼ŒæŒ‡å®šåˆ†æå“ªä¸ªäººç‰©æˆ–å…³æ³¨ä»€ä¹ˆç»†èŠ‚ï¼‰
    
    Returns:
        è§’è‰²æè¿°æ–‡æœ¬
    """
    _ensure_imports()
    
    genai.configure(api_key=api_key)
    
    try:
        # åŠ è½½å›¾åƒ
        image = PIL_Image.open(image_path)
        
        # åˆ›å»ºè§†è§‰æ¨¡å‹ï¼ˆå’Œä»£ç†æ¨¡å¼å®Œå…¨ä¸€è‡´ï¼Œä½¿ç”¨ gemini-2.0-flashï¼‰
        model = genai.GenerativeModel("gemini-2.0-flash")
        
        # æ„å»ºåˆ†ææç¤ºè¯
        analysis_prompt = """Analyze this image and provide a detailed character description for 3D modeling reference.

Focus on:
- Physical appearance (face, hair, body type)
- Clothing and accessories (materials, colors, details)
- Notable features or distinctive elements
- Overall style and aesthetic

Provide a clear, structured description that can be used to generate multi-view character references."""
        
        if user_guidance:
            analysis_prompt += f"\n\nUser guidance: {user_guidance}"
        
        # å‘é€è¯·æ±‚
        response = model.generate_content([analysis_prompt, image])
        
        if response.text:
            return response.text.strip()
        else:
            print("[WARNING] å›¾åƒåˆ†ææœªè¿”å›æ–‡æœ¬")
            return None
            
    except Exception as e:
        error_msg = str(e)
        
        # æ£€æµ‹é…é¢é”™è¯¯
        is_quota_error = (
            "429" in error_msg or 
            "quota" in error_msg.lower() or 
            "ResourceExhausted" in str(type(e).__name__)
        )
        
        if is_quota_error:
            print(f"\nâš ï¸  é…é¢é™åˆ¶: gemini-2.0-flash çš„å…è´¹é…é¢å·²ç”¨å®Œ")
            print(f"\nğŸ’¡ å»ºè®®: ä½¿ç”¨ä»£ç†æ¨¡å¼å¯é¿å…é…é¢é™åˆ¶")
            if original_args:
                base_cmd_parts = ["python scripts\\generate_character.py"]
                if hasattr(original_args, 'from_image') and original_args.from_image:
                    base_cmd_parts.append(f"--from-image {original_args.from_image}")
                if hasattr(original_args, 'strict') and original_args.strict:
                    base_cmd_parts.append("--strict")
                proxy_cmd = " ".join(base_cmd_parts + ["--mode proxy --token 'your-aiproxy-token'"])
                print(f"   {proxy_cmd}\n")
        else:
            print(f"[ERROR] å›¾åƒåˆ†æå¤±è´¥: {error_msg}")
        
        return None


def main():
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ Gemini API ç”Ÿæˆå››è§†è§’è§’è‰²è®¾è®¡å›¾"
    )
    parser.add_argument(
        "description",
        nargs="?",
        help="è§’è‰²æè¿° (ä¾‹å¦‚: 'æœ«æ—¥å¹¸å­˜è€…ï¼Œç©¿ç€ç ´æ—§è¥¿è£…')"
    )
    parser.add_argument(
        "--api-key",
        default=os.environ.get("GEMINI_API_KEY"),
        help="Gemini API Key (æˆ–è®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡)"
    )
    parser.add_argument(
        "--model",
        default=DEFAULT_MODEL,
        help="æ¨¡å‹åç§° (é»˜è®¤: gemini-2.0-flash-exp)"
    )
    parser.add_argument(
        "--output", "-o",
        default="test_images",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: test_images)"
    )
    parser.add_argument(
        "--no-cut",
        action="store_true",
        help="ä¸è‡ªåŠ¨åˆ‡å‰²å›¾åƒ"
    )
    parser.add_argument(
        "--interactive", "-i",
        action="store_true",
        help="äº¤äº’æ¨¡å¼"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ API Key
    if not args.api_key:
        print("[ERROR] è¯·è®¾ç½® Gemini API Key:")
        print("  export GEMINI_API_KEY='your-api-key'")
        print("  æˆ–ä½¿ç”¨ --api-key å‚æ•°")
        sys.exit(1)
    
    # äº¤äº’æ¨¡å¼
    if args.interactive or not args.description:
        print("\n" + "="*60)
        print("Gemini å¤šè§†è§’è§’è‰²å›¾åƒç”Ÿæˆå™¨ (äº¤äº’æ¨¡å¼)")
        print("="*60)
        print("\nè¯·æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„è§’è‰²:")
        print("(ä¾‹å¦‚: æœ«æ—¥å¹¸å­˜è€…ï¼Œç©¿ç€ç ´çƒ‚çš„è¥¿è£…ï¼Œæ‰‹æŒæ‰‹æª)")
        print("-"*60)
        
        description = input("\nè§’è‰²æè¿°: ").strip()
        if not description:
            print("[ERROR] è¯·è¾“å…¥è§’è‰²æè¿°")
            sys.exit(1)
    else:
        description = args.description
    
    # ç”Ÿæˆå›¾åƒ
    result = generate_character_views(
        character_description=description,
        api_key=args.api_key,
        model_name=args.model,
        output_dir=args.output,
        auto_cut=not args.no_cut
    )
    
    if result:
        print("\n" + "="*60)
        print("âœ… ç”Ÿæˆå®Œæˆ!")
        print("="*60)
        print(f"åŸå§‹å›¾åƒ: {result}")
        print(f"åˆ‡å‰²è§†å›¾: {args.output}/ ç›®å½•ä¸‹çš„ *_front.png, *_back.png ç­‰")
    else:
        print("\n[FAILED] å›¾åƒç”ŸæˆæœªæˆåŠŸ")
        sys.exit(1)


if __name__ == "__main__":
    main()
