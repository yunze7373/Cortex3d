#!/usr/bin/env python3
"""
Gemini å¤šè§†è§’å›¾åƒç”Ÿæˆå™¨
ä½¿ç”¨ Gemini API ç”Ÿæˆå››è§†å›¾è§’è‰²è®¾è®¡å›¾

ä½¿ç”¨å…±äº«é…ç½®: ä» config.py å¯¼å…¥æç¤ºè¯æ¨¡æ¿å’Œæ¨¡å‹åç§°

ä¾èµ–:
    pip install google-generativeai pillow
"""

import argparse
import os
import sys
from pathlib import Path
from datetime import datetime
from typing import Optional
import base64
import io

# å¯¼å…¥å…±äº«é…ç½®
from config import IMAGE_MODEL, build_multiview_prompt

# Lazy imports
genai = None
PIL_Image = None
cv2 = None
np = None


def _ensure_imports():
    """å»¶è¿Ÿå¯¼å…¥ä¾èµ–åº“"""
    global genai, PIL_Image, cv2, np
    
    if genai is None:
        try:
            import google.genai as _genai
            from PIL import Image as _Image
            from google.genai.types import HarmCategory, HarmBlockThreshold
            genai = _genai
            PIL_Image = _Image
        except ImportError as e:
            raise ImportError(
                f"ç¼ºå°‘å¿…è¦ä¾èµ–: {e}\n"
                "è¯·è¿è¡Œ: pip install google-genai pillow"
            )
    
    # å¯é€‰çš„ OpenCV å¯¼å…¥ï¼ˆç”¨äºå›¾åƒå¤„ç†ï¼‰
    if cv2 is None:
        try:
            import cv2 as _cv2
            import numpy as _np
            cv2 = _cv2
            np = _np
        except ImportError:
            pass  # å¦‚æœæ²¡æœ‰ opencvï¼ŒæŸäº›åŠŸèƒ½ä¼šè¢«ç¦ç”¨


# ä½¿ç”¨å…±äº«é…ç½®ä¸­çš„é»˜è®¤æ¨¡å‹ï¼ˆå’Œä»£ç†æ¨¡å¼å®Œå…¨ä¸€è‡´ï¼‰
DEFAULT_MODEL = IMAGE_MODEL  # models/nano-banana-pro-preview


# =============================================================================
# Gemini API è°ƒç”¨
# =============================================================================

def generate_character_views(
    character_description: str,
    api_key: str,
    model_name: str = DEFAULT_MODEL,
    output_dir: str = "test_images",
    auto_cut: bool = True,
    style: str = "cinematic character",
    view_mode: str = "4-view",
    custom_views: list = None,
    negative_prompt: str = None,
    reference_image_path: str = None,
    use_strict_mode: bool = False,
    resolution: str = "2K",
    original_args = None,
    export_prompt: bool = False,
    subject_only: bool = False,
    with_props: list = None
) -> Optional[str]:
    """
    ä½¿ç”¨ Gemini API ç”Ÿæˆå¤šè§†å›¾è§’è‰²å›¾åƒ
    
    Args:
        character_description: è§’è‰²æè¿°
        api_key: Gemini API Key
        model_name: æ¨¡å‹åç§°
        output_dir: è¾“å‡ºç›®å½•
        auto_cut: æ˜¯å¦è‡ªåŠ¨åˆ‡å‰²
        style: é£æ ¼æè¿°
        view_mode: è§†è§’æ¨¡å¼ (4-view, 6-view, 8-view, custom)
        custom_views: è‡ªå®šä¹‰è§†è§’åˆ—è¡¨
        negative_prompt: è´Ÿé¢æç¤ºè¯
        reference_image_path: å‚è€ƒå›¾åƒè·¯å¾„ï¼ˆç”¨äºå›¾ç”Ÿå›¾ï¼‰
        use_strict_mode: ä¸¥æ ¼å¤åˆ¶æ¨¡å¼ï¼ˆåŸºäºå‚è€ƒå›¾åƒï¼‰
        resolution: ç›®æ ‡åˆ†è¾¨ç‡ (1K/2K/4K)ï¼Œé€šè¿‡åå¤„ç†å®ç°
        subject_only: åªå¤„ç†ä¸»ä½“ï¼Œç§»é™¤èƒŒæ™¯ç‰©ä½“
        with_props: è¦åŒ…å«çš„é“å…·åˆ—è¡¨
    
    Returns:
        ç”Ÿæˆçš„å›¾ç‰‡è·¯å¾„
    """
    _ensure_imports()
    
    # é…ç½® API
    genai.configure(api_key=api_key)
    
    print("="*60)
    print("Gemini å¤šè§†è§’å›¾åƒç”Ÿæˆå™¨ (ç›´è¿æ¨¡å¼)")
    print("="*60)
    print(f"[æ¨¡å‹] {model_name}")
    print(f"[è§’è‰²æè¿°] {character_description[:100]}...")
    print(f"[é£æ ¼] {style}")
    print(f"[è§†è§’æ¨¡å¼] {view_mode}")
    if reference_image_path:
        mode_label = "ä¸¥æ ¼å¤åˆ¶" if use_strict_mode else "å‚è€ƒå›¾åƒ"
        print(f"[{mode_label}] {reference_image_path}")
    if subject_only:
        print(f"[ä¸»ä½“éš”ç¦»] åªå¤„ç†ä¸»ä½“äººç‰©ï¼Œç§»é™¤èƒŒæ™¯ç‰©ä½“")
    if with_props:
        print(f"[åŒ…å«é“å…·] {', '.join(with_props)}")
    print(f"[åˆ†è¾¨ç‡] {resolution}")
    print("-"*60)
    
    # å¤„ç†å‚è€ƒå›¾åƒï¼ˆè½¬ä¸º base64ï¼‰
    reference_image_b64 = None
    if reference_image_path:
        try:
            with open(reference_image_path, 'rb') as f:
                image_bytes = f.read()
            reference_image_b64 = base64.b64encode(image_bytes).decode('utf-8')
            # è·å– MIME ç±»å‹
            if reference_image_path.lower().endswith('.png'):
                mime = 'image/png'
            elif reference_image_path.lower().endswith(('.jpg', '.jpeg')):
                mime = 'image/jpeg'
            elif reference_image_path.lower().endswith('.webp'):
                mime = 'image/webp'
            else:
                mime = 'image/png'
            reference_image_b64 = f"data:{mime};base64,{reference_image_b64}"
            print(f"[INFO] å‚è€ƒå›¾åƒå·²åŠ è½½")
        except Exception as e:
            print(f"[WARNING] æ— æ³•åŠ è½½å‚è€ƒå›¾åƒ: {e}")
            reference_image_b64 = None
    
    # æ„å»ºæç¤ºè¯ï¼ˆå’Œä»£ç†æ¨¡å¼å®Œå…¨ä¸€è‡´ï¼‰
    if use_strict_mode and reference_image_b64:
        from config import build_strict_copy_prompt
        full_prompt = build_strict_copy_prompt(
            view_mode=view_mode,
            custom_views=custom_views,
            style=style,
            subject_only=subject_only,
            with_props=with_props
        )
        print("[æ¨¡å¼] ä¸¥æ ¼å¤åˆ¶ - 100% åŸºäºå‚è€ƒå›¾åƒ")
    elif reference_image_b64:
        from config import build_image_reference_prompt
        full_prompt = build_image_reference_prompt(
            character_description or "Extract character details and generate multi-view",
            view_mode=view_mode,
            custom_views=custom_views,
            style=style,
            subject_only=subject_only,
            with_props=with_props
        )
        print(f"[æ¨¡å¼] å›¾åƒå‚è€ƒ - æå–ç‰¹å¾ç”Ÿæˆ {view_mode if view_mode != 'custom' else str(custom_views)} è§†è§’")
    else:
        full_prompt = build_multiview_prompt(
            character_description, 
            style=style,
            view_mode=view_mode,
            custom_views=custom_views,
            subject_only=subject_only,
            with_props=with_props
        )
    
    # æ·»åŠ è´Ÿé¢æç¤ºè¯
    if negative_prompt:
        print(f"[è´Ÿé¢æç¤ºè¯] {negative_prompt[:60]}...")
    
    print("[INFO] æ­£åœ¨ç”Ÿæˆå›¾åƒ... (å¯èƒ½éœ€è¦ 30-60 ç§’)")
    
    try:
        # å‡†å¤‡ API è°ƒç”¨å‚æ•°ï¼ˆå’Œä»£ç†æ¨¡å¼å®Œå…¨å¯¹é½ï¼‰
        from google.genai.types import HarmCategory, HarmBlockThreshold
        
        # åˆ†è¾¨ç‡æ˜ å°„
        resolution_map = {
            "1K": "1K",
            "2K": "2K",
            "4K": "4K"
        }
        image_size = resolution_map.get(resolution, "2K")
        
        # å®½é«˜æ¯”ï¼ˆé»˜è®¤ 3:2 é€‚åˆå››è§†å›¾æ¨ªæ’ï¼‰
        aspect_ratio = "3:2"
        
        # æ„å»ºç”Ÿæˆé…ç½®
        generation_config = {
            "temperature": 0.7,
            "top_p": 0.95,
            "top_k": 40,
        }
        
        # å®‰å…¨è®¾ç½®ï¼ˆå’Œä»£ç†ä¸€è‡´ï¼‰
        safety_settings = [
            {"category": HarmCategory.HARM_CATEGORY_HARASSMENT, "threshold": HarmBlockThreshold.BLOCK_ONLY_HIGH},
            {"category": HarmCategory.HARM_CATEGORY_HATE_SPEECH, "threshold": HarmBlockThreshold.BLOCK_ONLY_HIGH},
            {"category": HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, "threshold": HarmBlockThreshold.BLOCK_ONLY_HIGH},
            {"category": HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, "threshold": HarmBlockThreshold.BLOCK_ONLY_HIGH},
        ]
        
        # å®šä¹‰å›é€€æ¨¡å‹ï¼ˆå’Œä»£ç†æ¨¡å¼å®Œå…¨ä¸€è‡´ï¼‰
        FALLBACK_MODELS = {
            "models/nano-banana-pro-preview": "gemini-2.5-flash-image",
            "nano-banana-pro-preview": "gemini-2.5-flash-image",
        }
        
        current_model = model_name
        MAX_RETRIES = 1
        
        for attempt in range(MAX_RETRIES + 1):
            print(f"[Gemini API] å°è¯•æ¨¡å‹: {current_model} (å°è¯• {attempt+1}/{MAX_RETRIES+1})")
            
            # åˆ›å»ºæ¨¡å‹
            model = genai.GenerativeModel(current_model)
        
            # åˆ›å»ºæ¨¡å‹
            model = genai.GenerativeModel(current_model)
        
            # å‡†å¤‡å†…å®¹åˆ—è¡¨
            contents = [full_prompt]
            
            # å¦‚æœæœ‰å‚è€ƒå›¾åƒï¼Œæ·»åŠ åˆ°å†…å®¹ä¸­
            if reference_image_b64:
                # è§£æ data URL
                if reference_image_b64.startswith('data:'):
                    header, b64_data = reference_image_b64.split(',', 1)
                    mime_type = header.split(';')[0].split(':')[1]
                else:
                    b64_data = reference_image_b64
                    mime_type = 'image/png'
                
                # æ·»åŠ å›¾åƒéƒ¨åˆ†
                contents.append({
                    'mime_type': mime_type,
                    'data': b64_data
                })
            
            # Gemini ä¼˜åŒ–ï¼šä½¿ç”¨è¯­ä¹‰è´Ÿé¢æç¤ºï¼ˆæ­£é¢æè¿°æ‰€éœ€åœºæ™¯ï¼‰
            # æ ¹æ® Gemini API æ–‡æ¡£å»ºè®®ï¼Œé¿å…ç›´æ¥åˆ—å‡ºç¦æ­¢é¡¹ï¼Œè€Œæ˜¯å¼ºè°ƒæ­£é¢è¦æ±‚
            if negative_prompt:
                # å°†ä¼ ç»Ÿè´Ÿé¢æç¤ºè¯è½¬æ¢ä¸ºè¯­ä¹‰æ­£é¢æŒ‡ä»¤
                semantic_avoidance = """
## ğŸ›¡ï¸ QUALITY REQUIREMENTS (what the image MUST have):
- Clean, anatomically correct figure with proper limb count and proportions
- Consistent pose maintained identically across all panels
- Head, gaze, and body orientation frozen in the same position in every view
- All limbs in exactly the same position and crossing order across views
- High quality, sharp details, no artifacts or distortions
- Clean panel layout with consistent sizing
- No text, labels, or overlays on the image"""
                contents[0] += semantic_avoidance
            
            # ===================================================================
            # å¯¼å‡ºæç¤ºè¯æ¨¡å¼ï¼šè¾“å‡ºå‚æ•°è€Œä¸è°ƒç”¨ API
            # ===================================================================
            if export_prompt:
                print("\n" + "="*70)
                print("ğŸ“‹ å¯¼å‡ºæç¤ºè¯å’Œå‚æ•° (å¤åˆ¶åˆ° Gemini App ä½¿ç”¨)")
                print("="*70)
                
                print(f"\nã€æ¨èæ¨¡å‹ã€‘")
                print(f"   nano-banana-pro-preview (æœ€ä½³å›¾åƒç”Ÿæˆæ¨¡å‹)")
                print(f"   å¤‡ç”¨: gemini-2.5-flash-image")
                print(f"   æç¤º: åœ¨ AI Studio æˆ– API ä¸­ä½¿ç”¨ä¸Šè¿°æ¨¡å‹åç§°")
                
                print(f"\nã€é…ç½®å‚æ•°å»ºè®®ã€‘")
                print(f"   åˆ†è¾¨ç‡: {image_size}")
                print(f"   å®½é«˜æ¯”: {aspect_ratio}")
                print(f"   Temperature: {generation_config.get('temperature', 0.7)}")
                print(f"   Top P: {generation_config.get('top_p', 0.95)}")
                print(f"   Top K: {generation_config.get('top_k', 40)}")
                
                print(f"\nã€å®Œæ•´æç¤ºè¯ã€‘")
                print("-"*70)
                print(contents[0])
                print("-"*70)
                
                # æ˜¾ç¤ºè´Ÿé¢æç¤ºè¯ä¿¡æ¯ï¼ˆåŸå§‹ç‰ˆæœ¬ï¼Œä¾›å‚è€ƒï¼‰
                if negative_prompt:
                    print(f"\nã€è´Ÿé¢æç¤ºè¯ä¿¡æ¯ã€‘")
                    print(f"   ğŸ“‹ åŸå§‹è´Ÿé¢æç¤ºè¯ (å·²è½¬æ¢ä¸ºè¯­ä¹‰æ­£é¢æŒ‡ä»¤):")
                    print(f"   {negative_prompt}")
                    print(f"   ")
                    print(f"   âœ… Gemini ä¼˜åŒ–: å·²è‡ªåŠ¨è½¬æ¢ä¸º 'QUALITY REQUIREMENTS' æ­£é¢æè¿°")
                    print(f"   ğŸ’¡ æ ¹æ® Gemini API æ–‡æ¡£å»ºè®®ï¼Œä½¿ç”¨è¯­ä¹‰è´Ÿé¢æç¤ºæ•ˆæœæ›´å¥½")
                
                if reference_image_b64:
                    print(f"\nã€âš ï¸  å‚è€ƒå›¾åƒ - é‡è¦ã€‘")
                    print(f"   æ–‡ä»¶è·¯å¾„: {reference_image_path}")
                    print(f"   å›¾åƒç±»å‹: {mime_type}")
                    print(f"   ")
                    print(f"   ğŸ“ æ“ä½œæ­¥éª¤:")
                    print(f"      1. åœ¨ Gemini App ä¸­ç‚¹å‡» ğŸ“ (é™„ä»¶) æŒ‰é’®")
                    print(f"      2. ä¸Šä¼ å›¾åƒ: {reference_image_path}")
                    print(f"      3. å›¾åƒä¼šæ˜¾ç¤ºåœ¨å¯¹è¯æ¡†ä¸­")
                    print(f"      4. ç„¶åç²˜è´´ä¸Šé¢çš„ã€å®Œæ•´æç¤ºè¯ã€‘")
                    if use_strict_mode:
                        print(f"   ")
                        print(f"   ğŸ¯ ä¸¥æ ¼æ¨¡å¼: ç”Ÿæˆçš„å›¾åƒå°† 100% åŸºäºä¸Šä¼ çš„å‚è€ƒå›¾")
                
                print(f"\nã€å®‰å…¨è®¾ç½®ã€‘")
                print(f"   éªšæ‰°: BLOCK_ONLY_HIGH")
                print(f"   ä»‡æ¨è¨€è®º: BLOCK_ONLY_HIGH")
                print(f"   æ€§æš—ç¤º: BLOCK_ONLY_HIGH")
                print(f"   å±é™©å†…å®¹: BLOCK_ONLY_HIGH")
                
                print(f"\n{'='*70}")
                print("ğŸ’¡ å®Œæ•´ä½¿ç”¨æµç¨‹:")
                print("="*70)
                print("\nç¬¬ä¸€æ­¥: æ‰“å¼€ Gemini App")
                print("   è®¿é—®: https://gemini.google.com")
                print("   æˆ–ä½¿ç”¨ Gemini ç§»åŠ¨åº”ç”¨")
                
                print("\nç¬¬äºŒæ­¥: é€‰æ‹©æ¨¡å‹")
                print("   åœ¨ AI Studio ä¸­ä½¿ç”¨: nano-banana-pro-preview")
                print("   æˆ–åœ¨ä»£ç ä¸­è°ƒç”¨: models/nano-banana-pro-preview")
                
                if reference_image_b64:
                    print("\nç¬¬ä¸‰æ­¥: ä¸Šä¼ å‚è€ƒå›¾åƒ âš ï¸ å…ˆä¸Šä¼ å›¾åƒ!")
                    print(f"   1. ç‚¹å‡»å¯¹è¯æ¡†å·¦ä¸‹è§’çš„ ğŸ“ (é™„ä»¶) å›¾æ ‡")
                    print(f"   2. é€‰æ‹©å›¾åƒæ–‡ä»¶: {reference_image_path}")
                    print(f"   3. ç­‰å¾…å›¾åƒä¸Šä¼ å¹¶æ˜¾ç¤ºåœ¨å¯¹è¯æ¡†ä¸­")
                    step_four = "ç¬¬å››æ­¥"
                else:
                    step_four = "ç¬¬ä¸‰æ­¥"
                
                print(f"\n{step_four}: ç²˜è´´æç¤ºè¯")
                print("   1. å¤åˆ¶ä¸Šé¢ã€å®Œæ•´æç¤ºè¯ã€‘éƒ¨åˆ†çš„å…¨éƒ¨å†…å®¹")
                print("   2. ç²˜è´´åˆ° Gemini å¯¹è¯æ¡†ä¸­")
                if reference_image_b64:
                    print("   3. ç¡®è®¤å›¾åƒå’Œæç¤ºè¯éƒ½å·²åœ¨å¯¹è¯æ¡†ä¸­")
                
                print(f"\nç¬¬{'äº”' if reference_image_b64 else 'å››'}æ­¥: å‘é€å¹¶ç­‰å¾…")
                print("   1. ç‚¹å‡»å‘é€æŒ‰é’®")
                print("   2. ç­‰å¾… 30-60 ç§’ç”Ÿæˆå®Œæˆ")
                print("   3. ç”Ÿæˆçš„å›¾åƒä¼šæ˜¾ç¤ºåœ¨å›å¤ä¸­")
                
                print(f"\nç¬¬{'å…­' if reference_image_b64 else 'äº”'}æ­¥: ä¿å­˜å›¾åƒ")
                print("   1. å³é”®ç‚¹å‡»ç”Ÿæˆçš„å›¾åƒ")
                print("   2. é€‰æ‹© 'ä¿å­˜å›¾ç‰‡ä¸º...'")
                print("   3. ä¿å­˜åˆ°æ‚¨çš„è¾“å‡ºç›®å½•")
                
                print("\n" + "="*70)
                print("âœ… æç¤º: å¦‚æœç”Ÿæˆå¤±è´¥,è¯·æ£€æŸ¥:")
                print("   - æ˜¯å¦é€‰æ‹©äº†æ”¯æŒå›¾åƒç”Ÿæˆçš„æ¨¡å‹")
                if reference_image_b64:
                    print("   - å‚è€ƒå›¾åƒæ˜¯å¦å·²æ­£ç¡®ä¸Šä¼ ")
                print("   - æç¤ºè¯æ˜¯å¦å®Œæ•´å¤åˆ¶(ä¸è¦é—æ¼ä»»ä½•éƒ¨åˆ†)")
                print("="*70 + "\n")
                
                # å¯¼å‡ºæ¨¡å¼ä¸‹ä¸å®é™…è°ƒç”¨ APIï¼Œç›´æ¥è¿”å›
                return None
            
            print(f"[Gemini API] è°ƒç”¨å‚æ•°: image_size={image_size}, aspect_ratio={aspect_ratio}")
            
            try:
                # è°ƒç”¨ Gemini API
                response = model.generate_content(
                    contents,
                    generation_config=generation_config,
                    safety_settings=safety_settings
                )
                
                # æ£€æŸ¥å“åº”
                if not response or not response.candidates:
                    print("[ERROR] ç”Ÿæˆå¤±è´¥: æ— è¿”å›å†…å®¹")
                    if attempt < MAX_RETRIES:
                        continue  # å°è¯•å›é€€æ¨¡å‹
                    return None
                
                # æå–å›¾åƒæ•°æ®
                image_data = None
                for part in response.candidates[0].content.parts:
                    if hasattr(part, 'inline_data') and part.inline_data:
                        if part.inline_data.mime_type.startswith('image/'):
                            image_data = part.inline_data.data
                            break
                
                if not image_data:
                    print("[ERROR] API æœªè¿”å›å›¾åƒæ•°æ®")
                    if attempt < MAX_RETRIES:
                        print(f"[INFO] å°è¯•ä½¿ç”¨å›é€€æ¨¡å‹...")
                        continue  # å°è¯•å›é€€æ¨¡å‹
                    print("[æç¤º] Gemini API å¯èƒ½ä¸æ”¯æŒè¯¥æ¨¡å‹çš„å›¾åƒç”Ÿæˆ")
                    print("       è¯·å°è¯•ä½¿ç”¨ --mode proxy é€šè¿‡ä»£ç†æœåŠ¡è®¿é—®")
                    return None
                
                # ä¿å­˜å›¾åƒ
                output_path = Path(output_dir)
                output_path.mkdir(parents=True, exist_ok=True)
                
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"character_{timestamp}.png"
                filepath = output_path / filename
                
                # è§£ç å¹¶ä¿å­˜
                image_bytes = base64.b64decode(image_data) if isinstance(image_data, str) else image_data
                image = PIL_Image.open(io.BytesIO(image_bytes))
                image.save(str(filepath))
                
                print(f"[ä¿å­˜] {filepath}")
                
                # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                break
                
            except Exception as e:
                error_msg = str(e)
                
                # æ£€æµ‹é…é¢é”™è¯¯ï¼ˆResourceExhausted / 429ï¼‰
                is_quota_error = (
                    "429" in error_msg or 
                    "quota" in error_msg.lower() or 
                    "ResourceExhausted" in str(type(e).__name__)
                )
                
                # æ£€æµ‹æ¨¡å‹ä¸å­˜åœ¨é”™è¯¯
                is_model_not_found = "not found" in error_msg.lower() or "404" in error_msg
                
                if is_quota_error:
                    print(f"\nâš ï¸  é…é¢é™åˆ¶")
                    print(f"   æ¨¡å‹ '{current_model}' çš„å…è´¹é…é¢å·²ç”¨å®Œ")
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦å›é€€æ¨¡å‹
                    if attempt < MAX_RETRIES:
                        fallback_model = FALLBACK_MODELS.get(current_model)
                        if fallback_model and fallback_model != current_model:
                            print(f"   â†’ è‡ªåŠ¨åˆ‡æ¢åˆ°å›é€€æ¨¡å‹: {fallback_model}")
                            current_model = fallback_model
                            continue  # é‡è¯•
                    
                    # å¦‚æœå·²ç»æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œç»™å‡ºå‹å¥½æç¤º
                    print(f"\n{'='*70}")
                    print(f"ğŸ’¡ è§£å†³æ–¹æ¡ˆ - è¯·é€‰æ‹©ä»¥ä¸‹ä»»ä¸€é€‰é¡¹:")
                    print(f"{'='*70}")
                    
                    # æ„å»ºåŸºäºå®é™…å‚æ•°çš„å‘½ä»¤
                    if original_args:
                        base_cmd_parts = ["python scripts\\generate_character.py"]
                        
                        # æ·»åŠ æè¿°æˆ–å›¾åƒè¾“å…¥
                        if hasattr(original_args, 'from_image') and original_args.from_image:
                            base_cmd_parts.append(f"--from-image {original_args.from_image}")
                        elif hasattr(original_args, 'description') and original_args.description:
                            base_cmd_parts.append(f'"{original_args.description}"')
                        
                        # æ·»åŠ å…¶ä»–å‚æ•°
                        if hasattr(original_args, 'strict') and original_args.strict:
                            base_cmd_parts.append("--strict")
                        if hasattr(original_args, 'resolution') and original_args.resolution and original_args.resolution != "2K":
                            base_cmd_parts.append(f"--resolution {original_args.resolution}")
                        if hasattr(original_args, 'views') and original_args.views and original_args.views != 4:
                            base_cmd_parts.append(f"--views {original_args.views}")
                        if hasattr(original_args, 'preprocess') and original_args.preprocess:
                            base_cmd_parts.append("--preprocess")
                        
                        proxy_cmd = " ".join(base_cmd_parts + ["--mode proxy --token 'your-aiproxy-token'"])
                        direct_cmd = " ".join(base_cmd_parts + ["--mode direct --token 'another-gemini-key'"])
                        
                        print(f"\nğŸ“Œ é€‰é¡¹ 1: åˆ‡æ¢åˆ°ä»£ç†æ¨¡å¼ (æ¨è)")
                        print(f"   {proxy_cmd}")
                        
                        print(f"\nğŸ“Œ é€‰é¡¹ 2: ä½¿ç”¨ä¸åŒçš„ Gemini API Key")
                        print(f"   {direct_cmd}")
                    else:
                        # é™çº§åˆ°é€šç”¨æç¤º
                        print(f"\nğŸ“Œ é€‰é¡¹ 1: åˆ‡æ¢åˆ°ä»£ç†æ¨¡å¼ (--mode proxy --token 'your-token')")
                        print(f"ğŸ“Œ é€‰é¡¹ 2: ä½¿ç”¨ä¸åŒçš„ API Key (--mode direct --token 'new-key')")
                    
                    print(f"\nğŸ“Œ é€‰é¡¹ 3: ç­‰å¾…é…é¢æ¢å¤ (24å°æ—¶å)")
                    print(f"ğŸ“Œ é€‰é¡¹ 4: å‡çº§ä»˜è´¹è®¡åˆ’ (https://ai.google.dev/pricing)")
                    
                    print(f"\n{'='*70}")
                    print(f"ğŸ’¬ æ¨èä½¿ç”¨ä»£ç†æ¨¡å¼ä»¥è·å¾—æœ€ä½³ä½“éªŒ")
                    print(f"{'='*70}\n")
                    return None
                    
                elif is_model_not_found:
                    print(f"\nâŒ æ¨¡å‹ä¸å­˜åœ¨: {current_model}")
                    
                    if attempt < MAX_RETRIES:
                        fallback_model = FALLBACK_MODELS.get(current_model)
                        if fallback_model and fallback_model != current_model:
                            print(f"   â†’ è‡ªåŠ¨åˆ‡æ¢åˆ°å›é€€æ¨¡å‹: {fallback_model}")
                            current_model = fallback_model
                            continue  # é‡è¯•
                    
                    # æ„å»ºåŸºäºå®é™…å‚æ•°çš„ä»£ç†æ¨¡å¼å‘½ä»¤
                    if original_args:
                        base_cmd_parts = ["python scripts\\generate_character.py"]
                        if hasattr(original_args, 'from_image') and original_args.from_image:
                            base_cmd_parts.append(f"--from-image {original_args.from_image}")
                        if hasattr(original_args, 'strict') and original_args.strict:
                            base_cmd_parts.append("--strict")
                        proxy_cmd = " ".join(base_cmd_parts + ["--mode proxy --token 'your-aiproxy-token'"])
                        print(f"   ğŸ’¡ å»ºè®®ä½¿ç”¨ä»£ç†æ¨¡å¼: {proxy_cmd}")
                    else:
                        print(f"   ğŸ’¡ å»ºè®®ä½¿ç”¨ä»£ç†æ¨¡å¼ (--mode proxy --token 'your-token')")
                    return None
                    
                else:
                    # å…¶ä»–æœªçŸ¥é”™è¯¯
                    print(f"\nâŒ ç”Ÿæˆå¤±è´¥: {error_msg}")
                    
                    # å°è¯•å›é€€æ¨¡å‹
                    if attempt < MAX_RETRIES:
                        fallback_model = FALLBACK_MODELS.get(current_model)
                        if fallback_model and fallback_model != current_model:
                            print(f"   â†’ å°è¯•å›é€€æ¨¡å‹: {fallback_model}")
                            current_model = fallback_model
                            continue  # é‡è¯•
                    
                    # æœ€åä¸€æ¬¡å°è¯•ï¼Œæ‰“å°è¯¦ç»†é”™è¯¯
                    print(f"\nğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
                    import traceback
                    traceback.print_exc()
                    return None
                # æˆåŠŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                break
                
            except Exception as e:
                error_msg = str(e)
                print(f"[ERROR] ç”Ÿæˆå¤±è´¥: {error_msg}")
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦å›é€€æ¨¡å‹
                if attempt < MAX_RETRIES:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯é…é¢é”™è¯¯æˆ–æ¨¡å‹ä¸æ”¯æŒé”™è¯¯
                    if "quota" in error_msg.lower() or "429" in error_msg or "not found" in error_msg.lower():
                        fallback_model = FALLBACK_MODELS.get(current_model)
                        if fallback_model and fallback_model != current_model:
                            print(f"âš ï¸  æ¨¡å‹ {current_model} è°ƒç”¨å¤±è´¥ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å›é€€æ¨¡å‹: {fallback_model}")
                            current_model = fallback_model
                            continue  # é‡è¯•
                
                # å¦‚æœæ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œæ‰“å°è¯¦ç»†é”™è¯¯å¹¶é€€å‡º
                if attempt >= MAX_RETRIES:
                    import traceback
                    traceback.print_exc()
                    return None
        
        # å¦‚æœæˆåŠŸä¿å­˜äº†å›¾åƒï¼Œç»§ç»­å¤„ç†
            try:
                from prompts.views import get_views_by_names, get_views_for_mode
                
                # è®¡ç®—æœŸæœ›çš„è§†è„šåˆ—è¡¨
                if view_mode == "custom" and custom_views:
                    expected_view_objs = get_views_by_names(custom_views)
                else:
                    expected_view_objs = get_views_for_mode(view_mode)
                expected_views = [v.name for v in expected_view_objs]
                
                cut_and_save(str(filepath), output_dir, expected_views=expected_views)
            except Exception as e:
                print(f"[WARNING] æ— æ³•è®¡ç®—æœŸæœ›è§†è§’: {e}, ä½¿ç”¨é»˜è®¤åˆ‡å‰²")
                cut_and_save(str(filepath), output_dir)
        
        return str(filepath)
        
    except Exception as e:
        print(f"[ERROR] ç”Ÿæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


# =============================================================================
# æ–°å¢ç¼–è¾‘åŠŸèƒ½ - P0 é«˜ä¼˜å…ˆçº§
# =============================================================================

def edit_character_elements(
    source_image_path: str,
    edit_instruction: str,
    character_description: str,
    api_key: str,
    model_name: str = None,  # é»˜è®¤ä½¿ç”¨ gemini-2.5-flash-image
    output_dir: str = "test_images",
    auto_cut: bool = True,
    style: str = "cinematic character",
    export_prompt: bool = False,
    subject_only: bool = False,
    with_props: list = None,
    mode: str = "proxy",  # æ–°å¢: æ”¯æŒ proxy/direct
    proxy_base_url: str = None
) -> Optional[str]:
    """
    ç¼–è¾‘è§’è‰²çš„å…ƒç´ (æ·»åŠ /ç§»é™¤/ä¿®æ”¹)
    
    ä½¿ç”¨ Gemini 2.5 Flash Image æ¨¡å‹è¿›è¡Œå›¾åƒç¼–è¾‘ï¼Œä¿æŒåŸå§‹é£æ ¼ã€å…‰ç…§å’Œé€è§†æ•ˆæœã€‚
    
    Args:
        source_image_path: æºå›¾åƒè·¯å¾„
        edit_instruction: ç¼–è¾‘æŒ‡ä»¤ ("add:xxx", "remove:xxx", "modify:xxx")
        character_description: è§’è‰²æè¿°
        api_key: API Key (ä»£ç†æ¨¡å¼ä¸º proxy tokenï¼Œç›´è¿æ¨¡å¼ä¸º Gemini API Key)
        model_name: æ¨¡å‹åç§° (é»˜è®¤: gemini-2.5-flash-image)
        output_dir: è¾“å‡ºç›®å½•
        auto_cut: æ˜¯å¦è‡ªåŠ¨åˆ‡å‰²
        style: é£æ ¼æè¿°
        export_prompt: æ˜¯å¦å¯¼å‡ºæç¤ºè¯
        subject_only: æ˜¯å¦ä»…ä¸»ä½“
        with_props: é…ä»¶åˆ—è¡¨
        mode: API è°ƒç”¨æ¨¡å¼ ("proxy" æˆ– "direct")
        proxy_base_url: ä»£ç†æœåŠ¡åœ°å€ (ä»… proxy æ¨¡å¼)
    
    Returns:
        ç¼–è¾‘åå›¾åƒçš„è·¯å¾„
    """
    from pathlib import Path
    from image_editor_utils import parse_edit_instruction, compose_edit_prompt, load_image_as_base64
    
    _ensure_imports()
    
    # ä½¿ç”¨æ­£ç¡®çš„å›¾åƒç¼–è¾‘æ¨¡å‹
    if not model_name:
        model_name = "gemini-2.5-flash-image"
    
    # è§£æç¼–è¾‘æŒ‡ä»¤
    edit_type, edit_detail = parse_edit_instruction(edit_instruction)
    
    print(f"\n[ç¼–è¾‘æ¨¡å¼] {edit_type.upper()}")
    print(f"  åŸå›¾: {Path(source_image_path).name}")
    print(f"  æ“ä½œ: {edit_detail}")
    print(f"  æ¨¡å‹: {model_name}")
    print(f"  è°ƒç”¨æ¨¡å¼: {mode.upper()}")
    
    # æ„å»ºæç¤ºè¯ - ä½¿ç”¨ Gemini å®˜æ–¹æ¨èçš„æ ¼å¼
    prompt = compose_edit_prompt(
        edit_type=edit_type,
        edit_instruction=edit_detail,
        character_description=character_description,
        additional_context=f"Style: {style}"
    )
    
    if export_prompt:
        print("\n[å¯¼å‡ºæ¨¡å¼] æç¤ºè¯å·²å¤åˆ¶åˆ°å‰ªè´´æ¿:")
        print("="*70)
        print(prompt)
        print("="*70)
        return None
    
    # æ ¹æ®æ¨¡å¼é€‰æ‹©è°ƒç”¨æ–¹å¼
    if mode == "proxy":
        return _edit_via_proxy(
            source_image_path=source_image_path,
            prompt=prompt,
            edit_type=edit_type,
            api_key=api_key,
            model_name=model_name,
            output_dir=output_dir,
            proxy_base_url=proxy_base_url
        )
    else:
        return _edit_via_direct(
            source_image_path=source_image_path,
            prompt=prompt,
            edit_type=edit_type,
            api_key=api_key,
            model_name=model_name,
            output_dir=output_dir
        )


def _edit_via_proxy(
    source_image_path: str,
    prompt: str,
    edit_type: str,
    api_key: str,
    model_name: str,
    output_dir: str,
    proxy_base_url: str = None
) -> Optional[str]:
    """é€šè¿‡ AiProxy ä»£ç†è¿›è¡Œå›¾åƒç¼–è¾‘"""
    import requests
    import base64
    from pathlib import Path
    
    proxy_base_url = proxy_base_url or os.environ.get("AIPROXY_BASE_URL", "https://bot.bigjj.click/aiproxy")
    
    # åŠ è½½æºå›¾åƒ
    with open(source_image_path, 'rb') as f:
        image_bytes = f.read()
    
    # åˆ¤æ–­ MIME ç±»å‹
    suffix = Path(source_image_path).suffix.lower()
    mime_map = {
        ".jpg": "image/jpeg",
        ".jpeg": "image/jpeg",
        ".png": "image/png",
        ".webp": "image/webp"
    }
    mime_type = mime_map.get(suffix, "image/jpeg")
    b64_image = base64.b64encode(image_bytes).decode("utf-8")
    
    # è°ƒç”¨ AiProxy
    endpoint = f"{proxy_base_url.rstrip('/')}/generate"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    payload = {
        "prompt": prompt,
        "model": model_name,
        "image": f"data:{mime_type};base64,{b64_image}",
        "safetySettings": [
            { "category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_ONLY_HIGH" },
            { "category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_ONLY_HIGH" },
            { "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_ONLY_HIGH" },
            { "category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_ONLY_HIGH" }
        ]
    }
    
    try:
        print(f"\n[AiProxy] è°ƒç”¨å›¾åƒç¼–è¾‘: {endpoint}")
        print(f"[AiProxy] æ¨¡å‹: {model_name}")
        
        response = requests.post(
            endpoint,
            headers=headers,
            json=payload,
            timeout=180
        )
        
        if response.status_code != 200:
            print(f"[ERROR] AiProxy è°ƒç”¨å¤±è´¥: {response.status_code}")
            print(f"        {response.text[:200]}")
            return None
        
        result = response.json()
        
        # æå–å›¾åƒæ•°æ® (ä» reply ä¸­æå–)
        reply = result.get("reply", "")
        
        # ä½¿ç”¨ aiproxy_client ä¸­çš„æå–å‡½æ•°
        from aiproxy_client import extract_image_from_reply
        image_data = extract_image_from_reply(reply)
        
        if not image_data:
            print("[ERROR] AiProxy å“åº”ä¸­æœªæ‰¾åˆ°å›¾åƒæ•°æ®")
            return None
        
        image_bytes, _ = image_data
        
        # ä¿å­˜ç¼–è¾‘åçš„å›¾åƒ
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = Path(output_dir) / f"{edit_type}_edited_{timestamp}.png"
        
        with open(output_path, 'wb') as f:
            f.write(image_bytes)
        
        print(f"âœ… ç¼–è¾‘å®Œæˆ: {output_path}")
        return str(output_path)
        
    except Exception as e:
        print(f"[ERROR] ä»£ç†ç¼–è¾‘å¤±è´¥: {e}")
        return None


def _edit_via_direct(
    source_image_path: str,
    prompt: str,
    edit_type: str,
    api_key: str,
    model_name: str,
    output_dir: str
) -> Optional[str]:
    """ç›´è¿ Gemini API è¿›è¡Œå›¾åƒç¼–è¾‘"""
    from pathlib import Path
    from image_editor_utils import load_image_as_base64
    
    _ensure_imports()
    
    # é…ç½® API
    if api_key:
        genai.configure(api_key=api_key)
    
    # åŠ è½½æºå›¾åƒ
    image_b64 = load_image_as_base64(source_image_path)
    if image_b64 is None:
        print(f"[ERROR] æ— æ³•åŠ è½½æºå›¾åƒ: {source_image_path}")
        return None
    
    # è·å–æ­£ç¡®çš„ MIME ç±»å‹
    ext = source_image_path.lower()
    if ext.endswith('.png'):
        mime_type = "image/png"
    elif ext.endswith('.webp'):
        mime_type = "image/webp"
    else:
        mime_type = "image/jpeg"
    
    try:
        # è°ƒç”¨ Gemini API - ä½¿ç”¨æ–°çš„ google.genai å®¢æˆ·ç«¯
        # æ³¨æ„: gemini-2.5-flash-image éœ€è¦ä½¿ç”¨æ–° SDK
        try:
            from google import genai as new_genai
            from google.genai import types
            from PIL import Image
            
            client = new_genai.Client(api_key=api_key)
            image_input = Image.open(source_image_path)
            
            print(f"\n[Gemini] è°ƒç”¨å›¾åƒç¼–è¾‘ API...")
            print(f"[Gemini] æ¨¡å‹: {model_name}")
            
            response = client.models.generate_content(
                model=model_name,
                contents=[prompt, image_input],
            )
            
            # æå–ç”Ÿæˆçš„å›¾åƒ
            for part in response.parts:
                if hasattr(part, 'inline_data') and part.inline_data is not None:
                    # ä¿å­˜ç¼–è¾‘åçš„å›¾åƒ
                    Path(output_dir).mkdir(parents=True, exist_ok=True)
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    output_path = Path(output_dir) / f"{edit_type}_edited_{timestamp}.png"
                    
                    image = part.as_image()
                    image.save(str(output_path))
                    
                    print(f"âœ… ç¼–è¾‘å®Œæˆ: {output_path}")
                    return str(output_path)
                elif hasattr(part, 'text') and part.text:
                    print(f"[Gemini å“åº”] {part.text[:200]}...")
            
            print("[ERROR] API æœªè¿”å›å›¾åƒæ•°æ®")
            return None
            
        except ImportError:
            # å›é€€åˆ°æ—§çš„ google.generativeai
            print("[INFO] ä½¿ç”¨æ—§ç‰ˆ google.generativeai SDK")
            
            model = genai.GenerativeModel(model_name)
            
            contents = [
                prompt,
                {
                    "inline_data": {
                        "mime_type": mime_type,
                        "data": image_b64
                    }
                }
            ]
            
            generation_config = genai.types.GenerationConfig(
                max_output_tokens=4096,
                temperature=0.7,
            )
            
            print(f"\n[Gemini] è°ƒç”¨å›¾åƒç¼–è¾‘ API...")
            response = model.generate_content(
                contents,
                generation_config=generation_config,
                safety_settings=[]
            )
            
            if not response or not response.candidates:
                print("[ERROR] ç¼–è¾‘å¤±è´¥: æ— è¿”å›å†…å®¹")
                return None
            
            # æå–ç”Ÿæˆçš„å›¾åƒ
            image_data = None
            for part in response.candidates[0].content.parts:
                if hasattr(part, 'inline_data') and part.inline_data:
                    if part.inline_data.mime_type.startswith('image/'):
                        image_data = part.inline_data.data
                        break
            
            if not image_data:
                print("[ERROR] API æœªè¿”å›å›¾åƒæ•°æ®")
                return None
            
            # ä¿å­˜ç¼–è¾‘åçš„å›¾åƒ
            Path(output_dir).mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = Path(output_dir) / f"{edit_type}_edited_{timestamp}.png"
            
            if isinstance(image_data, str):
                import base64
                image_bytes = base64.b64decode(image_data)
            else:
                image_bytes = image_data
            
            with open(output_path, 'wb') as f:
                f.write(image_bytes)
            
            print(f"âœ… ç¼–è¾‘å®Œæˆ: {output_path}")
            return str(output_path)
        
    except Exception as e:
        print(f"[ERROR] ç¼–è¾‘å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def refine_character_details(
    source_image_path: str,
    detail_part: str,  # "face", "hands", "pose", "custom"
    issue_description: str,
    character_description: str,
    api_key: str,
    model_name: str = None,  # é»˜è®¤ä½¿ç”¨ gemini-2.5-flash-image
    output_dir: str = "test_images",
    auto_cut: bool = True,
    export_prompt: bool = False,
    mode: str = "proxy",  # æ–°å¢: æ”¯æŒ proxy/direct
    proxy_base_url: str = None
) -> Optional[str]:
    """
    ä¼˜åŒ–è§’è‰²çš„ç‰¹å®šç»†èŠ‚éƒ¨ä½(è¯­ä¹‰é®ç›–)
    
    Args:
        source_image_path: æºå›¾åƒè·¯å¾„
        detail_part: è¦ä¼˜åŒ–çš„éƒ¨ä½ (face/hands/pose/custom)
        issue_description: é—®é¢˜æè¿°
        character_description: è§’è‰²æè¿°
        api_key: API Key (ä»£ç†æ¨¡å¼ä¸º proxy tokenï¼Œç›´è¿æ¨¡å¼ä¸º Gemini API Key)
        model_name: æ¨¡å‹åç§° (é»˜è®¤: gemini-2.5-flash-image)
        output_dir: è¾“å‡ºç›®å½•
        auto_cut: æ˜¯å¦è‡ªåŠ¨åˆ‡å‰²
        export_prompt: æ˜¯å¦å¯¼å‡ºæç¤ºè¯
        mode: API è°ƒç”¨æ¨¡å¼ ("proxy" æˆ– "direct")
        proxy_base_url: ä»£ç†æœåŠ¡åœ°å€ (ä»… proxy æ¨¡å¼)
    
    Returns:
        ä¼˜åŒ–åå›¾åƒçš„è·¯å¾„
    """
    from pathlib import Path
    from image_editor_utils import compose_refine_prompt, load_image_as_base64
    
    _ensure_imports()
    
    # ä½¿ç”¨æ­£ç¡®çš„å›¾åƒç¼–è¾‘æ¨¡å‹
    if not model_name:
        model_name = "gemini-2.5-flash-image"
    
    # æ„å»ºéƒ¨ä½æ ‡ç­¾
    part_labels = {
        'face': 'è„¸éƒ¨è¡¨æƒ…å’Œç‰¹å¾',
        'hands': 'æ‰‹æŒ‡å’Œæ‰‹éƒ¨ç»†èŠ‚',
        'pose': 'èº«ä½“å§¿åŠ¿',
        'eyes': 'çœ¼ç›å’Œè§†çº¿',
        'custom': issue_description
    }
    
    part_label = part_labels.get(detail_part, detail_part)
    
    print(f"\n[ç»†èŠ‚ä¼˜åŒ–] {detail_part.upper()}")
    print(f"  åŸå›¾: {Path(source_image_path).name}")
    print(f"  é—®é¢˜: {issue_description}")
    print(f"  æ¨¡å‹: {model_name}")
    print(f"  è°ƒç”¨æ¨¡å¼: {mode.upper()}")
    
    # æ„å»ºæç¤ºè¯
    prompt = compose_refine_prompt(
        detail_part=part_label,
        issue_description=issue_description,
        character_description=character_description,
        preservation_notes="ä¿æŒæ‰€æœ‰å…¶ä»–å…ƒç´ å®Œå…¨ç›¸åŒ"
    )
    
    if export_prompt:
        print("\n[å¯¼å‡ºæ¨¡å¼] æç¤ºè¯å·²å¤åˆ¶åˆ°å‰ªè´´æ¿:")
        print("="*70)
        print(prompt)
        print("="*70)
        return None
    
    # æ ¹æ®æ¨¡å¼é€‰æ‹©è°ƒç”¨æ–¹å¼ (å¤ç”¨ edit å‡½æ•°çš„ä»£ç†/ç›´è¿é€»è¾‘)
    if mode == "proxy":
        return _edit_via_proxy(
            source_image_path=source_image_path,
            prompt=prompt,
            edit_type=f"refined_{detail_part}",
            api_key=api_key,
            model_name=model_name,
            output_dir=output_dir,
            proxy_base_url=proxy_base_url
        )
    else:
        return _edit_via_direct(
            source_image_path=source_image_path,
            prompt=prompt,
            edit_type=f"refined_{detail_part}",
            api_key=api_key,
            model_name=model_name,
            output_dir=output_dir
        )


# =============================================================================
# P1 åŠŸèƒ½: é£æ ¼è½¬æ¢ (Style Transfer)
# =============================================================================

def style_transfer_character(
    source_image_path: str,
    style_preset: str,
    character_description: str,
    api_key: str,
    model_name: str = None,  # é»˜è®¤ä½¿ç”¨ gemini-2.5-flash-image
    output_dir: str = "test_images",
    custom_style: Optional[str] = None,
    preserve_details: bool = True,
    mode: str = "proxy",  # æ–°å¢: æ”¯æŒ proxy/direct
    proxy_base_url: str = None
) -> Optional[str]:
    """
    åº”ç”¨é£æ ¼è½¬æ¢åˆ°è§’è‰²å›¾åƒ
    
    Args:
        source_image_path: æºå›¾åƒè·¯å¾„
        style_preset: é£æ ¼é¢„è®¾ (anime/cinematic/oil-painting/watercolor/comic/3d)
        character_description: è§’è‰²æè¿°
        api_key: API Key (ä»£ç†æ¨¡å¼ä¸º proxy tokenï¼Œç›´è¿æ¨¡å¼ä¸º Gemini API Key)
        model_name: æ¨¡å‹åç§° (é»˜è®¤: gemini-2.5-flash-image)
        output_dir: è¾“å‡ºç›®å½•
        custom_style: è‡ªå®šä¹‰é£æ ¼æè¿° (è¦†ç›–é¢„è®¾)
        preserve_details: æ˜¯å¦ä¿ç•™åŸå§‹ç»†èŠ‚
        mode: API è°ƒç”¨æ¨¡å¼ ("proxy" æˆ– "direct")
        proxy_base_url: ä»£ç†æœåŠ¡åœ°å€ (ä»… proxy æ¨¡å¼)
    
    Returns:
        é£æ ¼è½¬æ¢åå›¾åƒçš„è·¯å¾„
    """
    from pathlib import Path
    from image_editor_utils import compose_style_transfer_prompt, load_image_as_base64
    
    _ensure_imports()
    
    # ä½¿ç”¨æ­£ç¡®çš„å›¾åƒç¼–è¾‘æ¨¡å‹
    if not model_name:
        model_name = "gemini-2.5-flash-image"
    
    # é£æ ¼é¢„è®¾æ˜ å°„
    style_presets = {
        "anime": "Japanese anime style with exaggerated features, bright colors, and expressive eyes",
        "cinematic": "Cinematic photorealistic style with professional lighting and composition",
        "oil-painting": "Classical oil painting style with visible brushstrokes and rich colors",
        "watercolor": "Watercolor painting style with soft edges and flowing pigments",
        "comic": "Comic book style with bold outlines and limited color palette",
        "3d": "3D rendered/CGI style with modern digital aesthetics"
    }
    
    # ç¡®å®šé£æ ¼æè¿°
    style_description = custom_style if custom_style else style_presets.get(style_preset, style_preset)
    
    print(f"\n[é£æ ¼è½¬æ¢æ¨¡å¼]")
    print(f"  æºå›¾: {Path(source_image_path).name}")
    print(f"  é£æ ¼: {style_preset}" + (f" (è‡ªå®šä¹‰)" if custom_style else ""))
    print(f"  æ¨¡å‹: {model_name}")
    print(f"  è°ƒç”¨æ¨¡å¼: {mode.upper()}")
    
    # æ„å»ºæç¤ºè¯
    prompt = compose_style_transfer_prompt(
        target_style=style_description,
        character_description=character_description
    )
    
    # ä¿ç•™ç»†èŠ‚çš„é¢å¤–æŒ‡ä»¤
    if preserve_details:
        prompt += "\n\nImportant: Preserve all anatomical details, proportions, and character identity while applying the style."
    
    # æ ¹æ®æ¨¡å¼é€‰æ‹©è°ƒç”¨æ–¹å¼ (å¤ç”¨ edit å‡½æ•°çš„ä»£ç†/ç›´è¿é€»è¾‘)
    if mode == "proxy":
        return _edit_via_proxy(
            source_image_path=source_image_path,
            prompt=prompt,
            edit_type=f"styled_{style_preset}",
            api_key=api_key,
            model_name=model_name,
            output_dir=output_dir,
            proxy_base_url=proxy_base_url
        )
    else:
        return _edit_via_direct(
            source_image_path=source_image_path,
            prompt=prompt,
            edit_type=f"styled_{style_preset}",
            api_key=api_key,
            model_name=model_name,
            output_dir=output_dir
        )


# =============================================================================
# P0 åŠŸèƒ½: é«˜ä¿çœŸç»†èŠ‚ä¿ç•™ç¼–è¾‘ (Preserve Detail Edit)
# =============================================================================

def preserve_detail_edit(
    main_image_path: str,
    instruction: str,
    preserve_details: str = None,
    element_image_path: str = None,
    api_key: str = None,
    model_name: str = None,
    output_dir: str = "test_images",
    output_name: str = None,
    mode: str = "proxy",
    proxy_base_url: str = None
) -> Optional[str]:
    """
    é«˜ä¿çœŸç»†èŠ‚ä¿ç•™ç¼–è¾‘
    
    åœ¨ä¿®æ”¹å›¾åƒæ—¶ä¿ç•™å…³é”®ç»†èŠ‚ï¼ˆå¦‚é¢éƒ¨ç‰¹å¾ã€å¾½æ ‡ä½ç½®ç­‰ï¼‰ã€‚
    é€‚ç”¨äºéœ€è¦ç²¾ç¡®æ§åˆ¶å“ªäº›å…ƒç´ ä¿æŒä¸å˜çš„åœºæ™¯ã€‚
    
    Args:
        main_image_path: ä¸»å›¾ç‰‡è·¯å¾„ï¼ˆåŒ…å«è¦ä¿ç•™ç»†èŠ‚çš„å›¾ç‰‡ï¼‰
        instruction: ä¿®æ”¹æŒ‡ä»¤
        preserve_details: è¦ä¿ç•™çš„å…³é”®ç»†èŠ‚æè¿°ï¼ˆå¦‚ "ä¿æŒå¥³æ€§çš„é¢éƒ¨ç‰¹å¾å®Œå…¨ä¸å˜"ï¼‰
        element_image_path: å¯é€‰çš„å…ƒç´ å›¾ç‰‡è·¯å¾„ï¼ˆå¦‚ logoã€é…é¥°ç­‰è¦æ·»åŠ çš„å…ƒç´ ï¼‰
        api_key: API Key
        model_name: æ¨¡å‹åç§° (é»˜è®¤: gemini-2.5-flash-image)
        output_dir: è¾“å‡ºç›®å½•
        output_name: è¾“å‡ºæ–‡ä»¶å (å¯é€‰)
        mode: API è°ƒç”¨æ¨¡å¼ ("proxy" æˆ– "direct")
        proxy_base_url: ä»£ç†æœåŠ¡åœ°å€ (ä»… proxy æ¨¡å¼)
    
    Returns:
        ç¼–è¾‘åå›¾åƒçš„è·¯å¾„
    
    ç¤ºä¾‹:
        # ç»™äººç‰© T æ¤æ·»åŠ  logoï¼Œä¿æŒé¢éƒ¨ä¸å˜
        preserve_detail_edit(
            main_image_path="woman.png",
            instruction="å°† logo æ·»åŠ åˆ°å¥¹çš„é»‘è‰² T æ¤ä¸Šï¼Œè®© logo çœ‹èµ·æ¥åƒè‡ªç„¶å°åœ¨é¢æ–™ä¸Š",
            preserve_details="ç¡®ä¿å¥³æ€§çš„é¢éƒ¨å’Œç‰¹å¾ä¿æŒå®Œå…¨ä¸å˜",
            element_image_path="logo.png"
        )
        
        # æ”¹å˜èƒŒæ™¯ä½†ä¿æŒäººç‰©ç»†èŠ‚
        preserve_detail_edit(
            main_image_path="portrait.png",
            instruction="å°†èƒŒæ™¯æ”¹ä¸ºæµ·æ»©æ—¥è½åœºæ™¯",
            preserve_details="ä¿æŒäººç‰©çš„é¢éƒ¨ã€å‘å‹ã€æœè£…çš„æ‰€æœ‰ç»†èŠ‚å®Œå…¨ä¸å˜"
        )
    """
    from pathlib import Path
    
    _ensure_imports()
    
    if not model_name:
        model_name = "gemini-2.5-flash-image"
    
    print(f"\n[é«˜ä¿çœŸç»†èŠ‚ä¿ç•™ç¼–è¾‘]")
    print(f"  ä¸»å›¾ç‰‡: {Path(main_image_path).name}")
    if element_image_path:
        print(f"  å…ƒç´ å›¾ç‰‡: {Path(element_image_path).name}")
    print(f"  ä¿®æ”¹æŒ‡ä»¤: {instruction[:80]}{'...' if len(instruction) > 80 else ''}")
    if preserve_details:
        print(f"  ä¿ç•™ç»†èŠ‚: {preserve_details[:80]}{'...' if len(preserve_details) > 80 else ''}")
    print(f"  æ¨¡å‹: {model_name}")
    print(f"  è°ƒç”¨æ¨¡å¼: {mode.upper()}")
    
    # æ„å»ºå®Œæ•´çš„æç¤ºè¯ï¼Œå¼ºè°ƒç»†èŠ‚ä¿ç•™
    full_prompt_parts = []
    
    # æ·»åŠ ä¿®æ”¹æŒ‡ä»¤
    full_prompt_parts.append(instruction)
    
    # æ·»åŠ ç»†èŠ‚ä¿ç•™è¦æ±‚
    if preserve_details:
        full_prompt_parts.append(f"\n\nCRITICAL REQUIREMENT: {preserve_details}")
    else:
        # é»˜è®¤çš„ç»†èŠ‚ä¿ç•™æç¤º
        full_prompt_parts.append("\n\nIMPORTANT: Preserve all fine details of the original subject, including facial features, expressions, and any identifying characteristics.")
    
    # æ·»åŠ è‡ªç„¶èåˆæç¤º
    if element_image_path:
        full_prompt_parts.append("\n\nThe added element should blend naturally with the original image, matching the lighting, perspective, and style of the original.")
    
    full_prompt = "".join(full_prompt_parts)
    
    # æ ¹æ®æ¨¡å¼é€‰æ‹©è°ƒç”¨æ–¹å¼
    if mode == "proxy":
        return _preserve_edit_via_proxy(
            main_image_path=main_image_path,
            element_image_path=element_image_path,
            prompt=full_prompt,
            api_key=api_key,
            model_name=model_name,
            output_dir=output_dir,
            output_name=output_name,
            proxy_base_url=proxy_base_url
        )
    else:
        return _preserve_edit_via_direct(
            main_image_path=main_image_path,
            element_image_path=element_image_path,
            prompt=full_prompt,
            api_key=api_key,
            model_name=model_name,
            output_dir=output_dir,
            output_name=output_name
        )


def _preserve_edit_via_proxy(
    main_image_path: str,
    element_image_path: str,
    prompt: str,
    api_key: str,
    model_name: str,
    output_dir: str,
    output_name: str = None,
    proxy_base_url: str = None
) -> Optional[str]:
    """é€šè¿‡ AiProxy ä»£ç†è¿›è¡Œé«˜ä¿çœŸç¼–è¾‘"""
    import requests
    import base64
    from pathlib import Path
    
    proxy_base_url = proxy_base_url or os.environ.get("AIPROXY_BASE_URL", "https://bot.bigjj.click/aiproxy")
    
    # å‡†å¤‡å›¾ç‰‡æ•°æ®
    images_data = []
    
    # ä¸»å›¾ç‰‡
    with open(main_image_path, 'rb') as f:
        main_bytes = f.read()
    suffix = Path(main_image_path).suffix.lower()
    mime_map = {".jpg": "image/jpeg", ".jpeg": "image/jpeg", ".png": "image/png", ".webp": "image/webp"}
    main_mime = mime_map.get(suffix, "image/jpeg")
    main_b64 = base64.b64encode(main_bytes).decode("utf-8")
    images_data.append(f"data:{main_mime};base64,{main_b64}")
    
    # å…ƒç´ å›¾ç‰‡ (å¯é€‰)
    if element_image_path:
        with open(element_image_path, 'rb') as f:
            elem_bytes = f.read()
        suffix = Path(element_image_path).suffix.lower()
        elem_mime = mime_map.get(suffix, "image/jpeg")
        elem_b64 = base64.b64encode(elem_bytes).decode("utf-8")
        images_data.append(f"data:{elem_mime};base64,{elem_b64}")
    
    # è°ƒç”¨ AiProxy
    endpoint = f"{proxy_base_url.rstrip('/')}/generate"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # æ ¹æ®å›¾ç‰‡æ•°é‡é€‰æ‹© payload æ ¼å¼
    if len(images_data) == 1:
        payload = {
            "prompt": prompt,
            "model": model_name,
            "image": images_data[0],
            "safetySettings": [
                { "category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_ONLY_HIGH" },
                { "category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_ONLY_HIGH" },
                { "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_ONLY_HIGH" },
                { "category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_ONLY_HIGH" }
            ]
        }
    else:
        payload = {
            "prompt": prompt,
            "model": model_name,
            "images": images_data,
            "safetySettings": [
                { "category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_ONLY_HIGH" },
                { "category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_ONLY_HIGH" },
                { "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_ONLY_HIGH" },
                { "category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_ONLY_HIGH" }
            ]
        }
    
    try:
        print(f"\n[AiProxy] è°ƒç”¨é«˜ä¿çœŸç¼–è¾‘: {endpoint}")
        print(f"[AiProxy] æ¨¡å‹: {model_name}")
        print(f"[AiProxy] å›¾ç‰‡æ•°é‡: {len(images_data)}")
        
        response = requests.post(
            endpoint,
            headers=headers,
            json=payload,
            timeout=180
        )
        
        if response.status_code != 200:
            print(f"[ERROR] AiProxy è°ƒç”¨å¤±è´¥: {response.status_code}")
            print(f"        {response.text[:200]}")
            return None
        
        result = response.json()
        
        # æå–å›¾åƒæ•°æ®
        reply = result.get("reply", "")
        from aiproxy_client import extract_image_from_reply
        image_data = extract_image_from_reply(reply)
        
        if not image_data:
            print("[ERROR] AiProxy å“åº”ä¸­æœªæ‰¾åˆ°å›¾åƒæ•°æ®")
            return None
        
        image_bytes, _ = image_data
        
        # ä¿å­˜ç¼–è¾‘åçš„å›¾åƒ
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        if output_name:
            filename = output_name if output_name.endswith('.png') else f"{output_name}.png"
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"preserve_edit_{timestamp}.png"
        
        output_path = Path(output_dir) / filename
        
        with open(output_path, 'wb') as f:
            f.write(image_bytes)
        
        print(f"âœ… é«˜ä¿çœŸç¼–è¾‘å®Œæˆ: {output_path}")
        return str(output_path)
        
    except Exception as e:
        print(f"[ERROR] ä»£ç†é«˜ä¿çœŸç¼–è¾‘å¤±è´¥: {e}")
        return None


def _preserve_edit_via_direct(
    main_image_path: str,
    element_image_path: str,
    prompt: str,
    api_key: str,
    model_name: str,
    output_dir: str,
    output_name: str = None
) -> Optional[str]:
    """ç›´è¿ Gemini API è¿›è¡Œé«˜ä¿çœŸç¼–è¾‘"""
    from pathlib import Path
    from PIL import Image
    
    try:
        # ä½¿ç”¨æ–°çš„ google.genai SDK
        from google import genai as new_genai
        
        client = new_genai.Client(api_key=api_key)
        
        # åŠ è½½å›¾ç‰‡
        main_img = Image.open(main_image_path)
        
        # æ„å»ºå†…å®¹
        if element_image_path:
            elem_img = Image.open(element_image_path)
            contents = [main_img, elem_img, prompt]
        else:
            contents = [main_img, prompt]
        
        print(f"\n[Gemini] è°ƒç”¨é«˜ä¿çœŸç¼–è¾‘ API...")
        print(f"[Gemini] æ¨¡å‹: {model_name}")
        
        response = client.models.generate_content(
            model=model_name,
            contents=contents,
        )
        
        # æå–ç”Ÿæˆçš„å›¾åƒ
        for part in response.parts:
            if hasattr(part, 'inline_data') and part.inline_data is not None:
                # ä¿å­˜ç¼–è¾‘åçš„å›¾åƒ
                Path(output_dir).mkdir(parents=True, exist_ok=True)
                
                if output_name:
                    filename = output_name if output_name.endswith('.png') else f"{output_name}.png"
                else:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"preserve_edit_{timestamp}.png"
                
                output_path = Path(output_dir) / filename
                
                image = part.as_image()
                image.save(str(output_path))
                
                print(f"âœ… ç¼–è¾‘å®Œæˆ: {output_path}")
                return str(output_path)
            elif hasattr(part, 'text') and part.text:
                print(f"[Gemini å“åº”] {part.text[:200]}...")
        
        print("[ERROR] API æœªè¿”å›å›¾åƒæ•°æ®")
        return None
        
    except ImportError:
        # å›é€€åˆ°æ—§çš„ google.generativeai
        print("[INFO] ä½¿ç”¨æ—§ç‰ˆ google.generativeai SDK")
        
        _ensure_imports()
        
        if api_key:
            genai.configure(api_key=api_key)
        
        import base64
        
        contents = []
        
        # ä¸»å›¾ç‰‡
        with open(main_image_path, 'rb') as f:
            main_bytes = f.read()
        suffix = Path(main_image_path).suffix.lower()
        main_mime = "image/png" if suffix == ".png" else "image/jpeg"
        main_b64 = base64.b64encode(main_bytes).decode("utf-8")
        contents.append({
            "inline_data": {"mime_type": main_mime, "data": main_b64}
        })
        
        # å…ƒç´ å›¾ç‰‡ (å¯é€‰)
        if element_image_path:
            with open(element_image_path, 'rb') as f:
                elem_bytes = f.read()
            suffix = Path(element_image_path).suffix.lower()
            elem_mime = "image/png" if suffix == ".png" else "image/jpeg"
            elem_b64 = base64.b64encode(elem_bytes).decode("utf-8")
            contents.append({
                "inline_data": {"mime_type": elem_mime, "data": elem_b64}
            })
        
        contents.append(prompt)
        
        try:
            model = genai.GenerativeModel(model_name)
            
            print(f"\n[Gemini] è°ƒç”¨é«˜ä¿çœŸç¼–è¾‘ API...")
            response = model.generate_content(
                contents,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=4096,
                    temperature=0.7,
                ),
                safety_settings=[]
            )
            
            if not response or not response.candidates:
                print("[ERROR] ç¼–è¾‘å¤±è´¥: æ— è¿”å›å†…å®¹")
                return None
            
            # æå–ç”Ÿæˆçš„å›¾åƒ
            image_data = None
            for part in response.candidates[0].content.parts:
                if hasattr(part, 'inline_data') and part.inline_data:
                    if part.inline_data.mime_type.startswith('image/'):
                        image_data = part.inline_data.data
                        break
            
            if not image_data:
                print("[ERROR] API æœªè¿”å›å›¾åƒæ•°æ®")
                return None
            
            # ä¿å­˜ç¼–è¾‘åçš„å›¾åƒ
            Path(output_dir).mkdir(parents=True, exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_path = Path(output_dir) / f"{edit_type}_edited_{timestamp}.png"
            
            if isinstance(image_data, str):
                image_bytes = base64.b64decode(image_data)
            else:
                image_bytes = image_data
            
            with open(output_path, 'wb') as f:
                f.write(image_bytes)
            
            print(f"âœ… ç¼–è¾‘å®Œæˆ: {output_path}")
            return str(output_path)
        
        except Exception as e:
            print(f"[ERROR] ç¼–è¾‘å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    except Exception as e:
        print(f"[ERROR] ç¼–è¾‘å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


# =============================================================================
# æ™ºèƒ½è¡£æœæå– (Smart Clothing Extraction)
# =============================================================================

def smart_extract_clothing(
    image_path: str,
    api_key: str,
    model_name: str = "gemini-2.5-flash-image",
    output_dir: str = "test_images",
    mode: str = "proxy",
    proxy_base_url: str = None,
) -> Optional[str]:
    """
    æ™ºèƒ½åˆ†æå›¾ç‰‡å¹¶æå–è¡£æœ
    
    å·¥ä½œæµç¨‹ï¼š
    1. AIåˆ†æå›¾ç‰‡ï¼šåˆ¤æ–­æ˜¯çº¯è¡£æœã€æœ‰èƒŒæ™¯çš„è¡£æœï¼Œè¿˜æ˜¯ç©¿ç€è¡£æœçš„äºº
    2. å»é™¤èƒŒæ™¯ï¼ˆå¦‚æœæœ‰ï¼‰
    3. æå–è¡£æœï¼ˆå¦‚æœæ˜¯ç©¿ç€è¡£æœçš„äººï¼‰
    4. è¿”å›å¤„ç†åçš„å›¾ç‰‡è·¯å¾„
    
    Args:
        image_path: è¡£æœå›¾ç‰‡è·¯å¾„
        api_key: APIå¯†é’¥
        model_name: ä½¿ç”¨çš„æ¨¡å‹
        output_dir: è¾“å‡ºç›®å½•
        mode: è°ƒç”¨æ¨¡å¼ (proxy/direct)
        proxy_base_url: ä»£ç†åœ°å€
    
    Returns:
        å¤„ç†åçš„å›¾ç‰‡è·¯å¾„ï¼Œå¤±è´¥è¿”å›None
    """
    from pathlib import Path
    import requests
    import base64
    
    _ensure_imports()
    
    print(f"  ğŸ” æ­¥éª¤1: AIåˆ†æå›¾ç‰‡å†…å®¹...")
    
    # =========================================================================
    # æ­¥éª¤1: ç”¨AIåˆ†æå›¾ç‰‡å†…å®¹
    # =========================================================================
    analysis_prompt = """Analyze this image and determine its content type:

1. **Pure clothing item**: Only clothing/garment visible, no person wearing it (may have background)
2. **Person wearing clothing**: A person is wearing the clothing
3. **Ambiguous**: Cannot clearly determine

Also check if there is a background:
- Has background: Yes/No
- Background type: (white/solid color/complex scene/transparent)

Please respond in this exact format:
Content: [Pure clothing item / Person wearing clothing / Ambiguous]
Has background: [Yes / No]
Background type: [description]
Clothing description: [brief description of the clothing]"""

    try:
        # æ ¹æ®æ¨¡å¼è°ƒç”¨AIåˆ†æ
        if mode == "proxy":
            analysis_result = _analyze_image_via_proxy(
                image_path=image_path,
                prompt=analysis_prompt,
                api_key=api_key,
                model_name=model_name,
                proxy_base_url=proxy_base_url
            )
        else:
            analysis_result = _analyze_image_via_direct(
                image_path=image_path,
                prompt=analysis_prompt,
                api_key=api_key,
                model_name=model_name
            )
        
        if not analysis_result:
            print(f"     âš ï¸ AIåˆ†æå¤±è´¥ï¼Œè·³è¿‡æ™ºèƒ½å¤„ç†")
            return None
        
        print(f"     ğŸ“‹ åˆ†æç»“æœ:\n{analysis_result}")
        
        # è§£æåˆ†æç»“æœ
        content_type = "unknown"
        has_background = False
        
        result_lower = analysis_result.lower()
        if "pure clothing" in result_lower or "only clothing" in result_lower:
            content_type = "pure_clothing"
        elif "person wearing" in result_lower or "wearing clothing" in result_lower:
            content_type = "person_wearing"
        
        if "has background: yes" in result_lower:
            has_background = True
        
        print(f"     âœ… æ£€æµ‹ç»“æœ: å†…å®¹={content_type}, èƒŒæ™¯={has_background}")
        
    except Exception as e:
        print(f"     âš ï¸ AIåˆ†æå‡ºé”™: {e}")
        print(f"     ä½¿ç”¨é»˜è®¤å¤„ç†æµç¨‹")
        content_type = "unknown"
        has_background = True
    
    # =========================================================================
    # æ­¥éª¤2: æ ¹æ®åˆ†æç»“æœè¿›è¡Œå¤„ç†
    # =========================================================================
    output_path_obj = Path(output_dir)
    output_path_obj.mkdir(parents=True, exist_ok=True)
    
    img_name = Path(image_path).stem
    
    # æƒ…å†µ1: çº¯è¡£æœï¼Œæ— èƒŒæ™¯ â†’ ç›´æ¥ä½¿ç”¨
    if content_type == "pure_clothing" and not has_background:
        print(f"  âœ… æ£€æµ‹åˆ°çº¯è¡£æœä¸”æ— èƒŒæ™¯ï¼Œç›´æ¥ä½¿ç”¨")
        return image_path
    
    # æƒ…å†µ2: çº¯è¡£æœï¼Œæœ‰èƒŒæ™¯ â†’ ä»…å»é™¤èƒŒæ™¯
    if content_type == "pure_clothing" and has_background:
        print(f"  ğŸ”ª æ­¥éª¤2: å»é™¤èƒŒæ™¯...")
        try:
            from image_processor import remove_background
            import cv2
            
            img = cv2.imread(image_path)
            if img is None:
                print(f"     âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡")
                return None
            
            processed = remove_background(img, model_name="birefnet-general")
            processed_path = output_path_obj / f"_extracted_nobg_{img_name}.png"
            cv2.imwrite(str(processed_path), processed)
            
            print(f"     âœ… èƒŒæ™¯å·²å»é™¤: {processed_path.name}")
            return str(processed_path)
            
        except Exception as e:
            print(f"     âš ï¸ å»é™¤èƒŒæ™¯å¤±è´¥: {e}")
            return image_path
    
    # æƒ…å†µ3: ç©¿ç€è¡£æœçš„äºº â†’ å»èƒŒæ™¯ + AIæå–è¡£æœ
    if content_type == "person_wearing":
        print(f"  ğŸ‘¤ æ£€æµ‹åˆ°ç©¿ç€è¡£æœçš„äºº")
        
        # æ­¥éª¤2a: å…ˆå»é™¤èƒŒæ™¯
        intermediate_path = image_path
        if has_background:
            print(f"  ğŸ”ª æ­¥éª¤2a: å»é™¤èƒŒæ™¯...")
            try:
                from image_processor import remove_background
                import cv2
                
                img = cv2.imread(image_path)
                if img is not None:
                    processed = remove_background(img, model_name="birefnet-general")
                    intermediate_path = output_path_obj / f"_temp_nobg_{img_name}.png"
                    cv2.imwrite(str(intermediate_path), processed)
                    print(f"     âœ… èƒŒæ™¯å·²å»é™¤")
                else:
                    print(f"     âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡ï¼Œä½¿ç”¨åŸå›¾")
            except Exception as e:
                print(f"     âš ï¸ å»é™¤èƒŒæ™¯å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå›¾")
        
        # æ­¥éª¤2b: AIæå–è¡£æœ
        print(f"  ğŸ¨ æ­¥éª¤2b: AIæå–è¡£æœ...")
        
        extraction_prompt = """Extract ONLY the clothing/garment from this image of a person wearing it.

Requirements:
- Remove the person completely
- Keep only the clothing item itself
- Maintain the clothing's original shape, color, and details
- Show the clothing as if it's displayed on its own (like in a product photo)
- Keep transparent background

Generate an image showing only the extracted clothing item."""

        try:
            # è°ƒç”¨AIç”Ÿæˆæå–åçš„è¡£æœå›¾ç‰‡
            if mode == "proxy":
                extracted_path = _extract_clothing_via_proxy(
                    image_path=str(intermediate_path),
                    prompt=extraction_prompt,
                    api_key=api_key,
                    model_name=model_name,
                    output_dir=str(output_path_obj),
                    output_name=f"_extracted_clothing_{img_name}.png",
                    proxy_base_url=proxy_base_url
                )
            else:
                extracted_path = _extract_clothing_via_direct(
                    image_path=str(intermediate_path),
                    prompt=extraction_prompt,
                    api_key=api_key,
                    model_name=model_name,
                    output_dir=str(output_path_obj),
                    output_name=f"_extracted_clothing_{img_name}.png"
                )
            
            if extracted_path:
                print(f"     âœ… è¡£æœæå–å®Œæˆ: {Path(extracted_path).name}")
                return extracted_path
            else:
                print(f"     âš ï¸ è¡£æœæå–å¤±è´¥ï¼Œä½¿ç”¨å»èƒŒæ™¯åçš„å›¾ç‰‡")
                return str(intermediate_path)
                
        except Exception as e:
            print(f"     âš ï¸ AIæå–å‡ºé”™: {e}")
            return str(intermediate_path)
    
    # é»˜è®¤: ä»…å»é™¤èƒŒæ™¯
    print(f"  ğŸ”ª æ­¥éª¤2: é»˜è®¤å¤„ç† - å»é™¤èƒŒæ™¯...")
    try:
        from image_processor import remove_background
        import cv2
        
        img = cv2.imread(image_path)
        if img is not None:
            processed = remove_background(img, model_name="birefnet-general")
            processed_path = output_path_obj / f"_extracted_default_{img_name}.png"
            cv2.imwrite(str(processed_path), processed)
            print(f"     âœ… å¤„ç†å®Œæˆ: {processed_path.name}")
            return str(processed_path)
    except Exception as e:
        print(f"     âš ï¸ å¤„ç†å¤±è´¥: {e}")
    
    return image_path


def _analyze_image_via_proxy(image_path, prompt, api_key, model_name, proxy_base_url=None):
    """é€šè¿‡ä»£ç†åˆ†æå›¾ç‰‡"""
    import requests
    import base64
    
    proxy_base_url = proxy_base_url or os.environ.get("AIPROXY_BASE_URL", "https://bot.bigjj.click/aiproxy")
    
    try:
        with open(image_path, 'rb') as f:
            image_bytes = f.read()
        
        suffix = Path(image_path).suffix.lower()
        mime_map = {".jpg": "image/jpeg", ".jpeg": "image/jpeg", ".png": "image/png", ".webp": "image/webp"}
        mime_type = mime_map.get(suffix, "image/jpeg")
        b64_image = base64.b64encode(image_bytes).decode("utf-8")
        
        # AiProxy ä½¿ç”¨ /generate ç«¯ç‚¹ï¼Œè€Œä¸æ˜¯ /chat/completions
        endpoint = f"{proxy_base_url.rstrip('/')}/generate"
        headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
        
        # AiProxy æ ¼å¼ï¼šä½¿ç”¨ prompt + image
        payload = {
            "prompt": prompt,
            "model": model_name,
            "image": f"data:{mime_type};base64,{b64_image}",
            "safetySettings": [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_ONLY_HIGH"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_ONLY_HIGH"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_ONLY_HIGH"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_ONLY_HIGH"}
            ]
        }
        
        response = requests.post(endpoint, headers=headers, json=payload, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            # AiProxy è¿”å›æ ¼å¼ï¼š{"reply": "æ–‡æœ¬å†…å®¹"}
            if "reply" in result:
                return result["reply"].strip()
            else:
                print(f"     [DEBUG] å“åº”æ ¼å¼å¼‚å¸¸ï¼Œç¼ºå°‘replyå­—æ®µ: {list(result.keys())}")
                return None
        else:
            print(f"     [DEBUG] APIè°ƒç”¨å¤±è´¥: {response.status_code}")
            print(f"     [DEBUG] å“åº”: {response.text[:200]}")
            return None
            
    except Exception as e:
        print(f"     [DEBUG] åˆ†æè¯·æ±‚å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return None


def _analyze_image_via_direct(image_path, prompt, api_key, model_name):
    """ç›´æ¥è°ƒç”¨Geminiåˆ†æå›¾ç‰‡"""
    try:
        _ensure_imports()
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        
        image = PIL_Image.open(image_path)
        response = model.generate_content([prompt, image])
        
        return response.text if response else None
        
    except Exception as e:
        print(f"     [DEBUG] ç›´è¿åˆ†æå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return None


def _extract_clothing_via_proxy(image_path, prompt, api_key, model_name, output_dir, output_name, proxy_base_url=None):
    """é€šè¿‡ä»£ç†æå–è¡£æœï¼ˆå›¾åƒç”Ÿæˆï¼‰"""
    import requests
    import base64
    from pathlib import Path
    
    try:
        proxy_base_url = proxy_base_url or os.environ.get("AIPROXY_BASE_URL", "https://bot.bigjj.click/aiproxy")
        
        with open(image_path, 'rb') as f:
            image_bytes = f.read()
        
        suffix = Path(image_path).suffix.lower()
        mime_map = {".jpg": "image/jpeg", ".jpeg": "image/jpeg", ".png": "image/png", ".webp": "image/webp"}
        mime_type = mime_map.get(suffix, "image/jpeg")
        b64_image = base64.b64encode(image_bytes).decode("utf-8")
        
        endpoint = f"{proxy_base_url.rstrip('/')}/generate"
        headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
        
        payload = {
            "prompt": prompt,
            "model": model_name,
            "image": f"data:{mime_type};base64,{b64_image}",
            "safetySettings": [
                {"category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_ONLY_HIGH"},
                {"category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_ONLY_HIGH"},
                {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_ONLY_HIGH"},
                {"category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_ONLY_HIGH"}
            ]
        }
        
        response = requests.post(endpoint, headers=headers, json=payload, timeout=120)
        
        if response.status_code == 200:
            result = response.json()
            if "image" in result:
                # ä¿å­˜å›¾ç‰‡
                output_path = Path(output_dir) / output_name
                
                image_data = result["image"]
                if image_data.startswith("data:"):
                    image_data = image_data.split(",", 1)[1]
                
                with open(output_path, "wb") as f:
                    f.write(base64.b64decode(image_data))
                
                return str(output_path)
            else:
                print(f"     [DEBUG] å“åº”ä¸­æ— imageå­—æ®µ: {result.keys()}")
                return None
        else:
            print(f"     [DEBUG] æå–APIè°ƒç”¨å¤±è´¥: {response.status_code}")
            print(f"     [DEBUG] å“åº”: {response.text[:200]}")
            return None
            
    except Exception as e:
        print(f"     [DEBUG] æå–è¯·æ±‚å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return None


def _extract_clothing_via_direct(image_path, prompt, api_key, model_name, output_dir, output_name):
    """ç›´æ¥è°ƒç”¨Geminiæå–è¡£æœ"""
    try:
        _ensure_imports()
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel(model_name)
        
        image = PIL_Image.open(image_path)
        response = model.generate_content([prompt, image])
        
        # Geminiå¯èƒ½è¿”å›ç”Ÿæˆçš„å›¾ç‰‡æˆ–æè¿°
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…APIå“åº”è°ƒæ•´
        if response and hasattr(response, 'candidates'):
            for part in response.candidates[0].content.parts:
                if hasattr(part, 'inline_data'):
                    output_path = Path(output_dir) / output_name
                    with open(output_path, 'wb') as f:
                        f.write(part.inline_data.data)
                    return str(output_path)
        
        return None
        
    except Exception as e:
        print(f"     [DEBUG] ç›´è¿æå–å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return None


# =============================================================================
# P0 åŠŸèƒ½: é«˜çº§åˆæˆ (Multi-Image Composite)
# =============================================================================

def composite_images(
    image_paths: list,
    instruction: str,
    api_key: str,
    model_name: str = None,
    output_dir: str = "test_images",
    output_name: str = None,
    mode: str = "proxy",
    proxy_base_url: str = None,
    composite_type: str = "auto",
    composite_prompt_template: str = None,
    export_prompt: bool = False,
    instruction_is_final: bool = False,
) -> Optional[str]:
    """
    ç»„åˆå¤šå¼ å›¾ç‰‡åˆ›å»ºæ–°åœºæ™¯
    
    ç”¨äºæ¢è¡£æœã€æ¢é…é¥°ã€åˆ›æ„æ‹¼è´´ã€äº§å“æ¨¡å‹ç­‰é«˜çº§åˆæˆåœºæ™¯ã€‚
    æ¨¡å‹ä¼šä¿æŒåŸå§‹å›¾ç‰‡çš„é£æ ¼ã€å…‰ç…§å’Œé€è§†æ•ˆæœã€‚
    
    Args:
        image_paths: è¦åˆæˆçš„å›¾ç‰‡è·¯å¾„åˆ—è¡¨ (è‡³å°‘2å¼ )
        instruction: åˆæˆæŒ‡ä»¤ï¼Œæè¿°å¦‚ä½•ç»„åˆè¿™äº›å›¾ç‰‡
        api_key: API Key (ä»£ç†æ¨¡å¼ä¸º proxy tokenï¼Œç›´è¿æ¨¡å¼ä¸º Gemini API Key)
        model_name: æ¨¡å‹åç§° (é»˜è®¤: gemini-2.5-flash-image)
        output_dir: è¾“å‡ºç›®å½•
        output_name: è¾“å‡ºæ–‡ä»¶å (å¯é€‰ï¼Œé»˜è®¤è‡ªåŠ¨ç”Ÿæˆ)
        mode: API è°ƒç”¨æ¨¡å¼ ("proxy" æˆ– "direct")
        proxy_base_url: ä»£ç†æœåŠ¡åœ°å€ (ä»… proxy æ¨¡å¼)
        composite_type: åˆæˆç±»å‹ ("clothing", "accessory", "general", "auto")
        composite_prompt_template: è‡ªå®šä¹‰åˆæˆæç¤ºè¯æ¨¡æ¿ (å¯é€‰)
        instruction_is_final: å¦‚æœä¸º Trueï¼Œinstruction å·²æ˜¯å®Œæ•´æç¤ºè¯ï¼Œä¸å†å¤„ç†
    
    Returns:
        åˆæˆåå›¾åƒçš„è·¯å¾„
    
    ç¤ºä¾‹:
        # æ¢è¡£æœ
        composite_images(
            image_paths=["model.png", "dress.png"],
            instruction="è®©æ¨¡ç‰¹ç©¿ä¸Šè¿™ä»¶è£™å­ï¼Œä¿æŒè‡ªç„¶çš„å…‰å½±æ•ˆæœ"
        )
        
        # æ¢é…é¥°
        composite_images(
            image_paths=["person.png", "hat.png", "bag.png"],
            instruction="ç»™äººç‰©æˆ´ä¸Šå¸½å­å¹¶æ‹¿ä¸ŠåŒ…åŒ…"
        )
    """
    from pathlib import Path
    
    _ensure_imports()
    
    if not model_name:
        model_name = "gemini-2.5-flash-image"
    
    # å•å›¾æ¨¡å¼æ£€æŸ¥ (åªæœ‰clothing_textç±»å‹æ”¯æŒå•å›¾)
    if len(image_paths) < 2:
        if composite_type != "clothing_text":
            print("[ERROR] åˆæˆéœ€è¦è‡³å°‘2å¼ å›¾ç‰‡ (é™¤éä½¿ç”¨ clothing_text æ¨¡å¼)")
            return None
        # å•å›¾æ¨¡å¼ - å…è®¸ç»§ç»­
    
    # ç¡®å®šæœ€ç»ˆæç¤ºè¯
    if instruction_is_final:
        # instruction å·²ç»æ˜¯å®Œæ•´çš„æç¤ºè¯ï¼Œç›´æ¥ä½¿ç”¨
        enhanced_instruction = instruction
    elif composite_prompt_template:
        # ä½¿ç”¨è‡ªå®šä¹‰æ¨¡æ¿
        image_list = "\n".join([f"Image {i+1}: {Path(p).name}" for i, p in enumerate(image_paths)])
        enhanced_instruction = composite_prompt_template.format(
            instruction=instruction,
            num_images=len(image_paths),
            image_list=image_list
        )
    else:
        # ä½¿ç”¨ config.py ä¸­çš„ä¸¥æ ¼æ¨¡æ¿ç³»ç»Ÿï¼ˆä¸å¤šè§†è§’ç”ŸæˆåŒçº§åˆ«ç²¾åº¦ï¼‰
        from config import build_composite_prompt
        enhanced_instruction = build_composite_prompt(
            instruction=instruction,
            composite_type=composite_type,
            num_images=len(image_paths)
        )
    
    print(f"\n[é«˜çº§åˆæˆ]")
    print(f"  è¾“å…¥å›¾ç‰‡: {len(image_paths)} å¼ ")
    for i, p in enumerate(image_paths, 1):
        print(f"    [{i}] {Path(p).name}")
    print(f"  ç”¨æˆ·æŒ‡ä»¤: {instruction[:80]}{'...' if len(instruction) > 80 else ''}")
    print(f"  åˆæˆç±»å‹: {composite_type}")
    print(f"  æ¨¡å‹: {model_name}")
    print(f"  è°ƒç”¨æ¨¡å¼: {mode.upper()}")
    
    # æ‰“å°æœ€ç»ˆæç¤ºè¯
    if export_prompt:
        print(f"\n{'='*60}")
        print("[æœ€ç»ˆåˆæˆæç¤ºè¯]")
        print(f"{'='*60}")
        print(enhanced_instruction)
        print(f"{'='*60}\n")
    
    # æ ¹æ®æ¨¡å¼é€‰æ‹©è°ƒç”¨æ–¹å¼
    if mode == "proxy":
        return _composite_via_proxy(
            image_paths=image_paths,
            instruction=enhanced_instruction,
            api_key=api_key,
            model_name=model_name,
            output_dir=output_dir,
            output_name=output_name,
            proxy_base_url=proxy_base_url
        )
    else:
        return _composite_via_direct(
            image_paths=image_paths,
            instruction=enhanced_instruction,
            api_key=api_key,
            model_name=model_name,
            output_dir=output_dir,
            output_name=output_name
        )


def _composite_via_proxy(
    image_paths: list,
    instruction: str,
    api_key: str,
    model_name: str,
    output_dir: str,
    output_name: str = None,
    proxy_base_url: str = None
) -> Optional[str]:
    """é€šè¿‡ AiProxy ä»£ç†è¿›è¡Œå¤šå›¾åˆæˆ"""
    import requests
    import base64
    from pathlib import Path
    
    proxy_base_url = proxy_base_url or os.environ.get("AIPROXY_BASE_URL", "https://bot.bigjj.click/aiproxy")
    
    # å‡†å¤‡å¤šå¼ å›¾ç‰‡çš„ base64 æ•°æ®
    images_data = []
    for img_path in image_paths:
        with open(img_path, 'rb') as f:
            image_bytes = f.read()
        
        suffix = Path(img_path).suffix.lower()
        mime_map = {
            ".jpg": "image/jpeg",
            ".jpeg": "image/jpeg",
            ".png": "image/png",
            ".webp": "image/webp"
        }
        mime_type = mime_map.get(suffix, "image/jpeg")
        b64_image = base64.b64encode(image_bytes).decode("utf-8")
        images_data.append({
            "mime_type": mime_type,
            "data": f"data:{mime_type};base64,{b64_image}"
        })
    
    # è°ƒç”¨ AiProxy - å¤šå›¾åˆæˆ
    endpoint = f"{proxy_base_url.rstrip('/')}/generate"
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # æ„å»º payload - å¤šå›¾åˆæˆéœ€è¦ç‰¹æ®Šæ ¼å¼
    # AiProxy éœ€è¦æ”¯æŒ images æ•°ç»„æˆ–å¤šä¸ª image å­—æ®µ
    payload = {
        "prompt": instruction,
        "model": model_name,
        "images": [img["data"] for img in images_data],  # å¤šå›¾æ•°ç»„
        "safetySettings": [
            { "category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_ONLY_HIGH" },
            { "category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_ONLY_HIGH" },
            { "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_ONLY_HIGH" },
            { "category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_ONLY_HIGH" }
        ]
    }
    
    try:
        print(f"\n[AiProxy] è°ƒç”¨å¤šå›¾åˆæˆ: {endpoint}")
        print(f"[AiProxy] æ¨¡å‹: {model_name}")
        print(f"[AiProxy] å›¾ç‰‡æ•°é‡: {len(images_data)}")
        
        response = requests.post(
            endpoint,
            headers=headers,
            json=payload,
            timeout=180
        )
        
        if response.status_code != 200:
            print(f"[ERROR] AiProxy è°ƒç”¨å¤±è´¥: {response.status_code}")
            print(f"        {response.text[:200]}")
            return None
        
        result = response.json()
        
        # æå–å›¾åƒæ•°æ®
        reply = result.get("reply", "")
        from aiproxy_client import extract_image_from_reply
        image_data = extract_image_from_reply(reply)
        
        if not image_data:
            print("[ERROR] AiProxy å“åº”ä¸­æœªæ‰¾åˆ°å›¾åƒæ•°æ®")
            return None
        
        image_bytes, _ = image_data
        
        # ä¿å­˜åˆæˆåçš„å›¾åƒ
        Path(output_dir).mkdir(parents=True, exist_ok=True)
        
        if output_name:
            filename = output_name if output_name.endswith('.png') else f"{output_name}.png"
        else:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"composite_{timestamp}.png"
        
        output_path = Path(output_dir) / filename
        
        with open(output_path, 'wb') as f:
            f.write(image_bytes)
        
        print(f"âœ… åˆæˆå®Œæˆ: {output_path}")
        return str(output_path)
        
    except Exception as e:
        print(f"[ERROR] ä»£ç†åˆæˆå¤±è´¥: {e}")
        return None


def _composite_via_direct(
    image_paths: list,
    instruction: str,
    api_key: str,
    model_name: str,
    output_dir: str,
    output_name: str = None
) -> Optional[str]:
    """ç›´è¿ Gemini API è¿›è¡Œå¤šå›¾åˆæˆ"""
    from pathlib import Path
    from PIL import Image
    
    try:
        # ä½¿ç”¨æ–°çš„ google.genai SDK
        from google import genai as new_genai
        
        client = new_genai.Client(api_key=api_key)
        
        # åŠ è½½æ‰€æœ‰å›¾ç‰‡
        images = []
        for img_path in image_paths:
            img = Image.open(img_path)
            images.append(img)
        
        # æ„å»ºå†…å®¹: [image1, image2, ..., instruction]
        contents = images + [instruction]
        
        print(f"\n[Gemini] è°ƒç”¨å¤šå›¾åˆæˆ API...")
        print(f"[Gemini] æ¨¡å‹: {model_name}")
        
        response = client.models.generate_content(
            model=model_name,
            contents=contents,
        )
        
        # æå–ç”Ÿæˆçš„å›¾åƒ
        for part in response.parts:
            if hasattr(part, 'inline_data') and part.inline_data is not None:
                # ä¿å­˜åˆæˆåçš„å›¾åƒ
                Path(output_dir).mkdir(parents=True, exist_ok=True)
                
                if output_name:
                    filename = output_name if output_name.endswith('.png') else f"{output_name}.png"
                else:
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"composite_{timestamp}.png"
                
                output_path = Path(output_dir) / filename
                
                image = part.as_image()
                image.save(str(output_path))
                
                print(f"âœ… åˆæˆå®Œæˆ: {output_path}")
                return str(output_path)
            elif hasattr(part, 'text') and part.text:
                print(f"[Gemini å“åº”] {part.text[:200]}...")
        
        print("[ERROR] API æœªè¿”å›å›¾åƒæ•°æ®")
        return None
        
    except ImportError:
        # å›é€€åˆ°æ—§çš„ google.generativeai
        print("[INFO] ä½¿ç”¨æ—§ç‰ˆ google.generativeai SDK")
        
        _ensure_imports()
        
        if api_key:
            genai.configure(api_key=api_key)
        
        # åŠ è½½å›¾ç‰‡å¹¶è½¬ä¸º base64
        import base64
        
        contents = []
        for img_path in image_paths:
            with open(img_path, 'rb') as f:
                image_bytes = f.read()
            
            suffix = Path(img_path).suffix.lower()
            mime_type = "image/png" if suffix == ".png" else "image/jpeg"
            b64_image = base64.b64encode(image_bytes).decode("utf-8")
            
            contents.append({
                "inline_data": {
                    "mime_type": mime_type,
                    "data": b64_image
                }
            })
        
        contents.append(instruction)
        
        try:
            model = genai.GenerativeModel(model_name)
            
            print(f"\n[Gemini] è°ƒç”¨å¤šå›¾åˆæˆ API...")
            response = model.generate_content(
                contents,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=4096,
                    temperature=0.7,
                ),
                safety_settings=[]
            )
            
            if not response or not response.candidates:
                print("[ERROR] åˆæˆå¤±è´¥: æ— è¿”å›å†…å®¹")
                return None
            
            # æå–ç”Ÿæˆçš„å›¾åƒ
            image_data = None
            for part in response.candidates[0].content.parts:
                if hasattr(part, 'inline_data') and part.inline_data:
                    if part.inline_data.mime_type.startswith('image/'):
                        image_data = part.inline_data.data
                        break
            
            if not image_data:
                print("[ERROR] API æœªè¿”å›å›¾åƒæ•°æ®")
                return None
            
            # ä¿å­˜åˆæˆåçš„å›¾åƒ
            Path(output_dir).mkdir(parents=True, exist_ok=True)
            
            if output_name:
                filename = output_name if output_name.endswith('.png') else f"{output_name}.png"
            else:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"composite_{timestamp}.png"
            
            output_path = Path(output_dir) / filename
            
            if isinstance(image_data, str):
                image_bytes = base64.b64decode(image_data)
            else:
                image_bytes = image_data
            
            with open(output_path, 'wb') as f:
                f.write(image_bytes)
            
            print(f"âœ… åˆæˆå®Œæˆ: {output_path}")
            return str(output_path)
            
        except Exception as e:
            print(f"[ERROR] åˆæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    except Exception as e:
        print(f"[ERROR] åˆæˆå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


# å·²ç§»é™¤ generate_with_imagen å’Œ generate_with_gemini_vision å‡½æ•°
# ç›´è¿æ¨¡å¼åº”è¯¥å’Œä»£ç†æ¨¡å¼ä½¿ç”¨ç›¸åŒçš„é€»è¾‘ï¼Œåªæ˜¯è®¿é—®è·¯å¾„ä¸åŒ


def cut_and_save(image_path: str, output_dir: str, expected_views: list = None):
    """
    è°ƒç”¨ image_processor åˆ‡å‰²å›¾åƒ
    """
    script_dir = Path(__file__).parent
    sys.path.insert(0, str(script_dir))
    
    try:
        from image_processor import process_quadrant_image
        
        print("\n[INFO] è‡ªåŠ¨åˆ‡å‰²å››è§†å›¾...")
        process_quadrant_image(
            input_path=image_path,
            output_dir=output_dir,
            remove_bg_flag=True,
            expected_views=expected_views,
            margin=5
        )
    except ImportError:
        print("[WARNING] æ— æ³•å¯¼å…¥ image_processorï¼Œè·³è¿‡è‡ªåŠ¨åˆ‡å‰²")
        print("[TIP] è¿è¡Œ: python scripts/image_processor.py " + image_path)
    except Exception as e:
        print(f"[WARNING] åˆ‡å‰²å¤±è´¥: {e}")


# åˆ†è¾¨ç‡æ§åˆ¶å·²åœ¨ API è°ƒç”¨æ—¶é€šè¿‡ image_size å‚æ•°æŒ‡å®š
# æ— éœ€åå¤„ç†è°ƒæ•´


def analyze_image_for_character(image_path: str, api_key: str, user_guidance: str = None, original_args = None) -> Optional[str]:
    """
    ä½¿ç”¨ Gemini åˆ†æå›¾ç‰‡ï¼Œæå–è§’è‰²ç‰¹å¾æè¿°
    
    Args:
        image_path: å›¾ç‰‡è·¯å¾„
        api_key: Gemini API Key
        user_guidance: ç”¨æˆ·æŒ‡å¯¼ï¼ˆå¯é€‰ï¼ŒæŒ‡å®šåˆ†æå“ªä¸ªäººç‰©æˆ–å…³æ³¨ä»€ä¹ˆç»†èŠ‚ï¼‰
    
    Returns:
        è§’è‰²æè¿°æ–‡æœ¬
    """
    _ensure_imports()
    
    genai.configure(api_key=api_key)
    
    try:
        # åŠ è½½å›¾åƒ
        image = PIL_Image.open(image_path)
        
        # åˆ›å»ºè§†è§‰æ¨¡å‹ï¼ˆå’Œä»£ç†æ¨¡å¼å®Œå…¨ä¸€è‡´ï¼Œä½¿ç”¨ gemini-2.0-flashï¼‰
        model = genai.GenerativeModel("gemini-2.0-flash")
        
        # æ„å»ºåˆ†ææç¤ºè¯
        analysis_prompt = """Analyze this image and provide a detailed character description for 3D modeling reference.

Focus on:
- Physical appearance (face, hair, body type)
- Clothing and accessories (materials, colors, details)
- Notable features or distinctive elements
- Overall style and aesthetic

Provide a clear, structured description that can be used to generate multi-view character references."""
        
        if user_guidance:
            analysis_prompt += f"\n\nUser guidance: {user_guidance}"
        
        # å‘é€è¯·æ±‚
        response = model.generate_content([analysis_prompt, image])
        
        if response.text:
            return response.text.strip()
        else:
            print("[WARNING] å›¾åƒåˆ†ææœªè¿”å›æ–‡æœ¬")
            return None
            
    except Exception as e:
        error_msg = str(e)
        
        # æ£€æµ‹é…é¢é”™è¯¯
        is_quota_error = (
            "429" in error_msg or 
            "quota" in error_msg.lower() or 
            "ResourceExhausted" in str(type(e).__name__)
        )
        
        if is_quota_error:
            print(f"\nâš ï¸  é…é¢é™åˆ¶: gemini-2.0-flash çš„å…è´¹é…é¢å·²ç”¨å®Œ")
            print(f"\nğŸ’¡ å»ºè®®: ä½¿ç”¨ä»£ç†æ¨¡å¼å¯é¿å…é…é¢é™åˆ¶")
            if original_args:
                base_cmd_parts = ["python scripts\\generate_character.py"]
                if hasattr(original_args, 'from_image') and original_args.from_image:
                    base_cmd_parts.append(f"--from-image {original_args.from_image}")
                if hasattr(original_args, 'strict') and original_args.strict:
                    base_cmd_parts.append("--strict")
                proxy_cmd = " ".join(base_cmd_parts + ["--mode proxy --token 'your-aiproxy-token'"])
                print(f"   {proxy_cmd}\n")
        else:
            print(f"[ERROR] å›¾åƒåˆ†æå¤±è´¥: {error_msg}")
        
        return None


def main():
    parser = argparse.ArgumentParser(
        description="ä½¿ç”¨ Gemini API ç”Ÿæˆå››è§†è§’è§’è‰²è®¾è®¡å›¾"
    )
    parser.add_argument(
        "description",
        nargs="?",
        help="è§’è‰²æè¿° (ä¾‹å¦‚: 'æœ«æ—¥å¹¸å­˜è€…ï¼Œç©¿ç€ç ´æ—§è¥¿è£…')"
    )
    parser.add_argument(
        "--api-key",
        default=os.environ.get("GEMINI_API_KEY"),
        help="Gemini API Key (æˆ–è®¾ç½® GEMINI_API_KEY ç¯å¢ƒå˜é‡)"
    )
    parser.add_argument(
        "--model",
        default=DEFAULT_MODEL,
        help="æ¨¡å‹åç§° (é»˜è®¤: gemini-2.0-flash-exp)"
    )
    parser.add_argument(
        "--output", "-o",
        default="test_images",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: test_images)"
    )
    parser.add_argument(
        "--no-cut",
        action="store_true",
        help="ä¸è‡ªåŠ¨åˆ‡å‰²å›¾åƒ"
    )
    parser.add_argument(
        "--interactive", "-i",
        action="store_true",
        help="äº¤äº’æ¨¡å¼"
    )
    
    args = parser.parse_args()
    
    # æ£€æŸ¥ API Key
    if not args.api_key:
        print("[ERROR] è¯·è®¾ç½® Gemini API Key:")
        print("  export GEMINI_API_KEY='your-api-key'")
        print("  æˆ–ä½¿ç”¨ --api-key å‚æ•°")
        sys.exit(1)
    
    # äº¤äº’æ¨¡å¼
    if args.interactive or not args.description:
        print("\n" + "="*60)
        print("Gemini å¤šè§†è§’è§’è‰²å›¾åƒç”Ÿæˆå™¨ (äº¤äº’æ¨¡å¼)")
        print("="*60)
        print("\nè¯·æè¿°ä½ æƒ³è¦ç”Ÿæˆçš„è§’è‰²:")
        print("(ä¾‹å¦‚: æœ«æ—¥å¹¸å­˜è€…ï¼Œç©¿ç€ç ´çƒ‚çš„è¥¿è£…ï¼Œæ‰‹æŒæ‰‹æª)")
        print("-"*60)
        
        description = input("\nè§’è‰²æè¿°: ").strip()
        if not description:
            print("[ERROR] è¯·è¾“å…¥è§’è‰²æè¿°")
            sys.exit(1)
    else:
        description = args.description
    
    # ç”Ÿæˆå›¾åƒ
    result = generate_character_views(
        character_description=description,
        api_key=args.api_key,
        model_name=args.model,
        output_dir=args.output,
        auto_cut=not args.no_cut
    )
    
    if result:
        print("\n" + "="*60)
        print("âœ… ç”Ÿæˆå®Œæˆ!")
        print("="*60)
        print(f"åŸå§‹å›¾åƒ: {result}")
        print(f"åˆ‡å‰²è§†å›¾: {args.output}/ ç›®å½•ä¸‹çš„ *_front.png, *_back.png ç­‰")
    else:
        print("\n[FAILED] å›¾åƒç”ŸæˆæœªæˆåŠŸ")
        sys.exit(1)


if __name__ == "__main__":
    main()
