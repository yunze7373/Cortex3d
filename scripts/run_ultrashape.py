#!/usr/bin/env python3
"""
UltraShape é€šç”¨ç»†åŒ–æ¨¡å—
æ”¯æŒç»†åŒ–ä»»ä½• 3D é‡å»ºæ¨¡å‹çš„è¾“å‡ºï¼šInstantMeshã€TripoSRã€TRELLIS.2ã€Hunyuan3D ç­‰

ç”¨æ³•:
    # ç»†åŒ–å•ä¸ªç½‘æ ¼æ–‡ä»¶
    python run_ultrashape.py --image image.png --mesh mesh.glb --output outputs/refined
    
    # ç»†åŒ– InstantMesh è¾“å‡º
    python run_ultrashape.py --image image.png --mesh outputs/instantmesh/latest.obj
    
    # å¿«é€Ÿé¢„è§ˆæ¨¡å¼ï¼ˆä½æ˜¾å­˜ï¼‰
    python run_ultrashape.py --image image.png --mesh mesh.glb --preset fast
    
    # é«˜è´¨é‡æ¨¡å¼
    python run_ultrashape.py --image image.png --mesh mesh.glb --preset high
"""

import os
import sys
import argparse
import logging
from pathlib import Path
import gc

import torch
import numpy as np
from PIL import Image

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# è·¯å¾„é…ç½®
SCRIPT_DIR = Path(__file__).parent.absolute()
PROJECT_ROOT = SCRIPT_DIR.parent
ULTRASHAPE_ROOT = Path("/opt/ultrashape")  # Docker å®¹å™¨å†…è·¯å¾„

# æ·»åŠ  UltraShape åˆ° Python è·¯å¾„
if ULTRASHAPE_ROOT.exists():
    sys.path.insert(0, str(ULTRASHAPE_ROOT))
    logging.info(f"âœ“ UltraShape æ¨¡å—è·¯å¾„: {ULTRASHAPE_ROOT}")
else:
    logging.warning(f"âš  UltraShape æœªå®‰è£…åœ¨ {ULTRASHAPE_ROOT}")
    logging.warning("  æç¤º: è¯·ä½¿ç”¨ 'make build-ultrashape' æ„å»º Docker å®¹å™¨")

# è´¨é‡é¢„è®¾é…ç½®
QUALITY_PRESETS = {
    "lowmem": {
        "steps": 20,
        "num_latents": 4096,
        "octree_res": 384,
        "chunk_size": 1024,
        "num_surface_points": 102400,
        "description": "ä½å†…å­˜æ¨¡å¼ï¼ˆ~1åˆ†é’Ÿï¼Œ6GB VRAMï¼‰",
        "low_vram": True,
        "max_memory_gb": 6
    },
    "fast": {
        "steps": 12,
        "num_latents": 8192,
        "octree_res": 512,
        "chunk_size": 2048,
        "num_surface_points": 204800,
        "description": "å¿«é€Ÿé¢„è§ˆï¼ˆ~30ç§’ï¼Œ8GB VRAMï¼‰",
        "low_vram": True,
        "max_memory_gb": 8
    },
    "balanced": {
        "steps": 30,
        "num_latents": 12288,
        "octree_res": 640,
        "chunk_size": 2048,
        "num_surface_points": 204800,
        "description": "æ ‡å‡†è´¨é‡ï¼ˆ~2åˆ†é’Ÿï¼Œå³°å€¼14GB VRAMï¼Œé€‚åˆ16GBæ˜¾å¡ï¼‰",
        "low_vram": True,
        "max_memory_gb": 14  # ä¸¥æ ¼å³°å€¼æ§åˆ¶
    },
    "high": {
        "steps": 50,
        "num_latents": 32768,
        "octree_res": 1024,
        "chunk_size": 8000,
        "num_surface_points": 409600,
        "description": "é«˜è´¨é‡ï¼ˆ~5åˆ†é’Ÿï¼Œ24GB VRAMï¼‰",
        "max_memory_gb": 24
    },
    "ultra": {
        "steps": 100,
        "num_latents": 32768,
        "octree_res": 2048,
        "chunk_size": 10000,
        "num_surface_points": 409600,
        "description": "è¶…é«˜è´¨é‡ï¼ˆ~10åˆ†é’Ÿï¼Œ32GB VRAMï¼‰",
        "max_memory_gb": 32
    }
}


def check_dependencies():
    """æ£€æŸ¥å¿…è¦ä¾èµ–"""
    try:
        from omegaconf import OmegaConf
        from ultrashape.pipelines import UltraShapePipeline
        from ultrashape.surface_loaders import SharpEdgeSurfaceLoader
        from ultrashape.utils.misc import instantiate_from_config
        from ultrashape.utils import voxelize_from_point
        logging.info("âœ“ UltraShape ä¾èµ–åŠ è½½æˆåŠŸ")
        
        # åº”ç”¨ dtype ä¿®å¤è¡¥ä¸
        apply_dtype_fix()
        
        return True
    except ImportError as e:
        logging.error(f"âœ— ç¼ºå°‘ä¾èµ–: {e}")
        logging.error("  è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ Docker å®¹å™¨ä¸­è¿è¡Œ")
        return False


def apply_dtype_fix():
    """
    ä¿®å¤ UltraShape æ··åˆç²¾åº¦é—®é¢˜
    RuntimeError: expected scalar type Float but found Half
    """
    try:
        import torch.nn as nn
        import torch.nn.functional as F
        from ultrashape.models.denoisers import dit_mask
        
        # 1. ä¿®å¤ scaled_dot_product_attention
        original_sdpa = F.scaled_dot_product_attention
        
        def patched_sdpa(query, key, value, attn_mask=None, dropout_p=0.0, is_causal=False, scale=None):
            """ç¡®ä¿ q, k, v ç±»å‹ä¸€è‡´ä¸º float32"""
            query = query.float()
            key = key.float()
            value = value.float()
            if attn_mask is not None:
                attn_mask = attn_mask.float()
            return original_sdpa(
                query, key, value,
                attn_mask=attn_mask,
                dropout_p=dropout_p,
                is_causal=is_causal,
                scale=scale
            )
        
        F.scaled_dot_product_attention = patched_sdpa
        
        # 2. ä¿®å¤ F.linear å‡½æ•°ï¼ˆMoE å±‚ä½¿ç”¨ï¼‰
        original_f_linear = F.linear
        
        def patched_f_linear(input, weight, bias=None):
            """å¼ºåˆ¶ F.linear è¾“å…¥æƒé‡éƒ½ä¸º float32"""
            input = input.float()
            weight = weight.float()
            if bias is not None:
                bias = bias.float()
            return original_f_linear(input, weight, bias)
        
        F.linear = patched_f_linear
        
        # 3. ä¿®å¤æ‰€æœ‰ nn.Linear æ¨¡å—
        original_linear_forward = nn.Linear.forward
        
        def patched_linear_forward(self, input):
            """å¼ºåˆ¶çº¿æ€§å±‚è¾“å…¥è¾“å‡ºä¸º float32"""
            if self.weight.dtype != torch.float32:
                self.weight.data = self.weight.data.float()
            if self.bias is not None and self.bias.dtype != torch.float32:
                self.bias.data = self.bias.data.float()
            input = input.float()
            return original_linear_forward(self, input)
        
        nn.Linear.forward = patched_linear_forward
        
        # 4. ä¿®å¤ LayerNorm å±‚
        original_layernorm_forward = nn.LayerNorm.forward
        
        def patched_layernorm_forward(self, input):
            """å¼ºåˆ¶ LayerNorm è¾“å…¥è¾“å‡ºä¸º float32"""
            if self.weight is not None and self.weight.dtype != torch.float32:
                self.weight.data = self.weight.data.float()
            if self.bias is not None and self.bias.dtype != torch.float32:
                self.bias.data = self.bias.data.float()
            input = input.float()
            return original_layernorm_forward(self, input)
        
        nn.LayerNorm.forward = patched_layernorm_forward
        
        logging.info("âœ“ UltraShape dtype ä¿®å¤è¡¥ä¸å·²åº”ç”¨ (SDPA + F.linear + nn.Linear + LayerNorm)")
        
    except Exception as e:
        logging.warning(f"âš  dtype è¡¥ä¸åº”ç”¨å¤±è´¥: {e}")
        logging.warning("  å°†å°è¯•ç»§ç»­è¿è¡Œï¼Œä½†å¯èƒ½ä¼šé‡åˆ° dtype é”™è¯¯")


def check_dependencies():
    """æ£€æŸ¥å¿…è¦ä¾èµ–"""
    try:
        from omegaconf import OmegaConf
        from ultrashape.pipelines import UltraShapePipeline
        from ultrashape.surface_loaders import SharpEdgeSurfaceLoader
        from ultrashape.utils.misc import instantiate_from_config
        from ultrashape.utils import voxelize_from_point
        logging.info("âœ“ UltraShape ä¾èµ–åŠ è½½æˆåŠŸ")
        
        # åº”ç”¨ dtype ä¿®å¤è¡¥ä¸
        apply_dtype_fix()
        
        return True
    except ImportError as e:
        logging.error(f"âœ— ç¼ºå°‘ä¾èµ–: {e}")
        logging.error("  è¯·ç¡®ä¿åœ¨æ­£ç¡®çš„ Docker å®¹å™¨ä¸­è¿è¡Œ")
        return False


def load_ultrashape_pipeline(config_path, ckpt_path, device='cuda', low_vram=False):
    """åŠ è½½ UltraShape æµæ°´çº¿"""
    from omegaconf import OmegaConf
    from ultrashape.utils.misc import instantiate_from_config
    from ultrashape.pipelines import UltraShapePipeline
    
    logging.info("æ­£åœ¨åŠ è½½ UltraShape æ¨¡å‹...")
    
    # åŠ è½½é…ç½®
    config = OmegaConf.load(config_path)
    
    # å®ä¾‹åŒ–æ¨¡å‹ç»„ä»¶
    logging.info("  - åŠ è½½ VAE...")
    vae = instantiate_from_config(config.model.params.vae_config)
    
    logging.info("  - åŠ è½½ DiT...")
    dit = instantiate_from_config(config.model.params.dit_cfg)
    
    logging.info("  - åŠ è½½è°ƒåº¦å™¨...")
    scheduler = instantiate_from_config(config.model.params.scheduler_cfg)
    
    logging.info("  - åŠ è½½æ¡ä»¶ç¼–ç å™¨...")
    conditioner = instantiate_from_config(config.model.params.conditioner_config)
    
    logging.info("  - åŠ è½½å›¾åƒå¤„ç†å™¨...")
    image_processor = instantiate_from_config(config.model.params.image_processor_cfg)
    
    # åŠ è½½æƒé‡
    logging.info(f"  - åŠ è½½æƒé‡: {ckpt_path}")
    if not Path(ckpt_path).exists():
        raise FileNotFoundError(f"æƒé‡æ–‡ä»¶ä¸å­˜åœ¨: {ckpt_path}")
    
    weights = torch.load(ckpt_path, map_location='cpu')
    
    # å¼ºåˆ¶è½¬æ¢æƒé‡ä¸º float32ï¼ˆæƒé‡æ–‡ä»¶å¯èƒ½ä¿å­˜ä¸º float16ï¼‰
    logging.info("  - è½¬æ¢æƒé‡ä¸º float32...")
    for key in ['vae', 'dit', 'conditioner']:
        if key in weights:
            for param_key in weights[key]:
                if torch.is_tensor(weights[key][param_key]):
                    weights[key][param_key] = weights[key][param_key].float()
    
    vae.load_state_dict(weights['vae'], strict=True)
    dit.load_state_dict(weights['dit'], strict=True)
    conditioner.load_state_dict(weights['conditioner'], strict=True)
    
    # ç§»åŠ¨åˆ°è®¾å¤‡å¹¶å¼ºåˆ¶ float32
    vae.to(device).float()
    dit.to(device).float()
    conditioner.to(device).float()
    
    # é€’å½’å¼ºåˆ¶æ‰€æœ‰å­æ¨¡å—ã€å‚æ•°å’Œç¼“å†²åŒºéƒ½æ˜¯ float32
    def force_float32(module):
        """é€’å½’å¼ºåˆ¶æ¨¡å—æ‰€æœ‰ç»„ä»¶è½¬æ¢ä¸º float32"""
        module.float()
        for child in module.children():
            force_float32(child)
        for param in module.parameters(recurse=False):
            param.data = param.data.float()
        for buffer in module.buffers(recurse=False):
            buffer.data = buffer.data.float()
    
    logging.info("  - å¼ºåˆ¶è½¬æ¢æ‰€æœ‰æ¨¡å‹ç»„ä»¶ä¸º float32...")
    force_float32(vae)
    force_float32(dit)
    force_float32(conditioner)
    
    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    vae.eval()
    dit.eval()
    conditioner.eval()
    
    # å¯ç”¨ FlashVDM åŠ é€Ÿï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if hasattr(vae, 'enable_flashvdm_decoder'):
        # vae.enable_flashvdm_decoder()
        logging.info("  âœ“ FlashVDM åŠ é€Ÿå·²è·³è¿‡ (å¼ºåˆ¶ Float32)")
    
    # åˆ›å»ºæµæ°´çº¿
    logging.info("  - åˆ›å»ºæ¨ç†æµæ°´çº¿...")
    pipeline = UltraShapePipeline(
        vae=vae,
        model=dit,
        scheduler=scheduler,
        conditioner=conditioner,
        image_processor=image_processor
    )
    
    # ä½æ˜¾å­˜ä¼˜åŒ–
    if low_vram:
        pipeline.enable_model_cpu_offload()
        logging.info("  âœ“ ä½æ˜¾å­˜æ¨¡å¼å·²å¯ç”¨ï¼ˆCPU offloadingï¼‰")
        
        # å°è¯•å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            if hasattr(dit, 'enable_gradient_checkpointing'):
                dit.enable_gradient_checkpointing()
                logging.info("  âœ“ æ¢¯åº¦æ£€æŸ¥ç‚¹å·²å¯ç”¨")
        except Exception as e:
            logging.debug(f"  - æ¢¯åº¦æ£€æŸ¥ç‚¹ä¸å¯ç”¨: {e}")
    
    logging.info("âœ“ UltraShape æµæ°´çº¿åŠ è½½å®Œæˆ")
    return pipeline, config


def load_surface_from_mesh(mesh_path, normalize_scale=0.99, num_points=409600):
    """ä»ç½‘æ ¼æ–‡ä»¶åŠ è½½è¡¨é¢ç‚¹äº‘"""
    from ultrashape.surface_loaders import SharpEdgeSurfaceLoader
    
    logging.info(f"æ­£åœ¨åŠ è½½ç½‘æ ¼: {mesh_path}")
    
    # åˆå§‹åŒ–è¡¨é¢åŠ è½½å™¨ - å¯é…ç½®é‡‡æ ·ç‚¹æ•°
    # åˆ†é…ï¼š50% å‡åŒ€é‡‡æ · + 50% å°–é”è¾¹ç¼˜é‡‡æ ·
    num_sharp = num_points // 2
    num_uniform = num_points - num_sharp
    
    logging.info(f"  - é‡‡æ ·ç‚¹æ•°: {num_points} (å‡åŒ€: {num_uniform}, è¾¹ç¼˜: {num_sharp})")
    
    loader = SharpEdgeSurfaceLoader(
        num_sharp_points=num_sharp,
        num_uniform_points=num_uniform
    )
    
    # åŠ è½½å¹¶é‡‡æ ·ç½‘æ ¼
    surface_pcd = loader(str(mesh_path))
    
    # å½’ä¸€åŒ–
    if normalize_scale != 1.0:
        surface_pcd = surface_pcd * normalize_scale
    
    logging.info(f"  âœ“ è¡¨é¢ç‚¹äº‘åŠ è½½å®Œæˆ: {surface_pcd.shape}")
    return surface_pcd


def refine_mesh(
    image_path,
    mesh_path,
    output_dir,
    ckpt_path="checkpoints/ultrashape_v1.pt",
    config_path="configs/infer_dit_refine.yaml",
    preset="balanced",
    steps=None,
    num_latents=None,
    octree_res=None,
    chunk_size=None,
    guidance_scale=5.0,
    scale=0.99,
    seed=42,
    low_vram=False,
    remove_bg=False
):
    """
    UltraShape ç»†åŒ–ä¸»å‡½æ•°
    
    Args:
        image_path: å‚è€ƒå›¾åƒè·¯å¾„
        mesh_path: ç²—ç³™ç½‘æ ¼è·¯å¾„ï¼ˆ.glb/.objï¼‰
        output_dir: è¾“å‡ºç›®å½•
        preset: è´¨é‡é¢„è®¾ (fast/balanced/high/ultra)
        steps: æ¨ç†æ­¥æ•°ï¼ˆè¦†ç›–é¢„è®¾ï¼‰
        num_latents: æ½œåœ¨ token æ•°é‡ï¼ˆè¦†ç›–é¢„è®¾ï¼‰
        octree_res: Marching Cubes åˆ†è¾¨ç‡ï¼ˆè¦†ç›–é¢„è®¾ï¼‰
        chunk_size: æ‰¹å¤„ç†å—å¤§å°ï¼ˆè¦†ç›–é¢„è®¾ï¼‰
        low_vram: ä½æ˜¾å­˜æ¨¡å¼
    """
    
    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        return None
    
    from ultrashape.utils import voxelize_from_point
    from ultrashape.rembg import BackgroundRemover
    import trimesh
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(seed)
    np.random.seed(seed)
    
    # åº”ç”¨è´¨é‡é¢„è®¾
    if preset in QUALITY_PRESETS:
        preset_config = QUALITY_PRESETS[preset]
        logging.info(f"ğŸ“Š ä½¿ç”¨è´¨é‡é¢„è®¾: {preset} - {preset_config['description']}")
        
        steps = steps or preset_config["steps"]
        num_latents = num_latents or preset_config["num_latents"]
        octree_res = octree_res or preset_config["octree_res"]
        chunk_size = chunk_size or preset_config["chunk_size"]
        num_surface_points = preset_config.get("num_surface_points", 409600)
        max_memory_gb = preset_config.get("max_memory_gb", None)
        
        # å¦‚æœé¢„è®¾å¯ç”¨ä½æ˜¾å­˜æ¨¡å¼ï¼Œå¼ºåˆ¶å¼€å¯
        if preset_config.get("low_vram", False):
            low_vram = True
            logging.info("  âš™ï¸  è‡ªåŠ¨å¯ç”¨ CPU offloading (ä½æ˜¾å­˜ä¼˜åŒ–)")
    else:
        logging.warning(f"æœªçŸ¥é¢„è®¾ '{preset}'ï¼Œä½¿ç”¨é»˜è®¤å€¼")
        steps = steps or 30
        num_latents = num_latents or 16384
        octree_res = octree_res or 768
        chunk_size = chunk_size or 4000
        num_surface_points = 409600
        max_memory_gb = None
    
    # è®¾å¤‡é…ç½®
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    logging.info(f"ğŸ–¥ï¸  è®¾å¤‡: {device}")
    
    # è®¾ç½®ä¸¥æ ¼çš„æ˜¾å­˜é™åˆ¶
    if max_memory_gb and torch.cuda.is_available():
        max_memory_bytes = int(max_memory_gb * 1024 * 1024 * 1024)
        torch.cuda.set_per_process_memory_fraction(max_memory_gb / 16.0)  # å‡è®¾16GBæ˜¾å¡
        logging.info(f"  ğŸ”’ ä¸¥æ ¼é™åˆ¶æ˜¾å­˜: {max_memory_gb}GB (å³°å€¼ä¿æŠ¤)")
        
        # è®¾ç½® PyTorch ç¼“å­˜åˆ†é…å™¨ä¸ºä¿å®ˆæ¨¡å¼
        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
    
    # ç¡®ä¿è·¯å¾„å­˜åœ¨
    mesh_path = Path(mesh_path)
    image_path = Path(image_path)
    output_dir = Path(output_dir)
    output_dir.mkdir(parents=True, exist_ok=True)
    
    if not mesh_path.exists():
        raise FileNotFoundError(f"ç½‘æ ¼æ–‡ä»¶ä¸å­˜åœ¨: {mesh_path}")
    if not image_path.exists():
        raise FileNotFoundError(f"å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}")
    
    # åŠ è½½é…ç½®è·¯å¾„
    config_path = ULTRASHAPE_ROOT / config_path
    ckpt_path = Path(ckpt_path)
    if not ckpt_path.is_absolute():
        # å°è¯•å¤šä¸ªå¯èƒ½çš„è·¯å¾„
        possible_paths = [
            Path("/workspace/checkpoints") / ckpt_path.name,
            Path("/workspace/models/ultrashape") / ckpt_path.name,
            ULTRASHAPE_ROOT / ckpt_path,
            Path("models/ultrashape") / ckpt_path.name  # ç›¸å¯¹è·¯å¾„ fallback
        ]
        
        found = False
        for p in possible_paths:
            if p.exists():
                ckpt_path = p
                found = True
                logging.info(f"  âœ“ æ‰¾åˆ°æƒé‡æ–‡ä»¶: {ckpt_path}")
                break
        
        if not found:
            # é»˜è®¤å›é€€åˆ° ULTRASHAPE_ROOTï¼Œè®©åç»­æŠ¥é”™
            ckpt_path = ULTRASHAPE_ROOT / ckpt_path
    
    if not config_path.exists():
        logging.error(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return None
    
    # åŠ è½½æµæ°´çº¿
    pipeline, config = load_ultrashape_pipeline(
        config_path=str(config_path),
        ckpt_path=str(ckpt_path),
        device=device,
        low_vram=low_vram
    )
    
    # è·å–ä½“ç´ åˆ†è¾¨ç‡
    voxel_res = config.model.params.vae_config.params.voxel_query_res
    logging.info(f"ğŸ“ ä½“ç´ åˆ†è¾¨ç‡: {voxel_res}")
    
    # åŠ è½½è¡¨é¢ç‚¹äº‘
    surface_pcd = load_surface_from_mesh(mesh_path, normalize_scale=scale, num_points=num_surface_points)
    
    # ä½“ç´ åŒ–æ¡ä»¶
    logging.info(f"ğŸ§Š ç”Ÿæˆä½“ç´ æ¡ä»¶ (Token æ•°: {num_latents})...")
    voxel_cond, _ = voxelize_from_point(
        surface_pcd[:, :, :3],
        resolution=voxel_res,
        num_latents=num_latents
    )
    
    # ä½æ˜¾å­˜æ¨¡å¼ï¼šå…ˆä¸ç§»åˆ° GPU
    if not low_vram:
        voxel_cond = voxel_cond.to(device)
    logging.info(f"  âœ“ ä½“ç´ æ¡ä»¶: {voxel_cond.shape}")
    
    # åŠ è½½å›¾åƒ
    logging.info(f"ğŸ–¼ï¸  åŠ è½½å›¾åƒ: {image_path}")
    image = Image.open(image_path)
    
    # ç§»é™¤èƒŒæ™¯ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if remove_bg or image.mode != 'RGBA':
        logging.info("  - ç§»é™¤èƒŒæ™¯...")
        rembg = BackgroundRemover()
        image = rembg(image)
    
    # è¿è¡Œç»†åŒ–
    logging.info("\n" + "="*60)
    logging.info("ğŸš€ å¼€å§‹ UltraShape ç»†åŒ–...")
    logging.info(f"  - æ¨ç†æ­¥æ•°: {steps}")
    logging.info(f"  - å¼•å¯¼å¼ºåº¦: {guidance_scale}")
    logging.info(f"  - å…«å‰æ ‘åˆ†è¾¨ç‡: {octree_res}")
    logging.info(f"  - å—å¤§å°: {chunk_size}")
    logging.info("="*60 + "\n")
    
    try:
        # ä½æ˜¾å­˜æ¨¡å¼ï¼šæ¿€è¿›çš„å†…å­˜æ¸…ç†
        if low_vram:
            gc.collect()
            torch.cuda.empty_cache()
            logging.info("  ğŸ§¹ æ¸…ç†æ˜¾å­˜å®Œæˆ")
            
            # å¼ºåˆ¶åŒæ­¥ï¼Œç¡®ä¿æ¸…ç†å®Œæˆ
            if torch.cuda.is_available():
                torch.cuda.synchronize()
        
        # å¼ºåˆ¶ç¦ç”¨ AMP å’Œæ¢¯åº¦ï¼Œç¡®ä¿å…¨ç¨‹ float32 + æ— æ¢¯åº¦
        with torch.cuda.amp.autocast(enabled=False), torch.no_grad():
            # ç¡®ä¿è¾“å…¥å¼ é‡ä¹Ÿæ˜¯ float32
            if voxel_cond.dtype != torch.float32:
                voxel_cond = voxel_cond.float()
            
            # ä½æ˜¾å­˜æ¨¡å¼ï¼šåˆ†æ‰¹ç§»åˆ° GPU
            if low_vram and voxel_cond.device.type != 'cuda':
                logging.info("  ğŸ“¦ åˆ†æ‰¹åŠ è½½åˆ° GPU...")
                voxel_cond = voxel_cond.to(device)
                
                # ç«‹å³æ¸…ç†å¹¶åŒæ­¥
                gc.collect()
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
                
                # æ‰“å°å½“å‰æ˜¾å­˜ä½¿ç”¨
                if torch.cuda.is_available():
                    allocated = torch.cuda.memory_allocated() / 1024**3
                    reserved = torch.cuda.memory_reserved() / 1024**3
                    logging.info(f"  ğŸ’¾ æ˜¾å­˜: {allocated:.2f}GB å·²ç”¨, {reserved:.2f}GB å·²ä¿ç•™")
            
            outputs = pipeline(
                image=image,
                voxel_cond=voxel_cond,
                num_inference_steps=steps,
                guidance_scale=guidance_scale,
                octree_resolution=octree_res,
                num_chunks=chunk_size,
                output_type="trimesh",
                enable_pbar=True
            )
        
        # ä¿å­˜ç»“æœ
        output_name = mesh_path.stem + "_refined"
        output_path = output_dir / f"{output_name}.glb"
        
        logging.info(f"\nğŸ’¾ ä¿å­˜ç»†åŒ–ç½‘æ ¼: {output_path}")
        outputs[0].export(str(output_path))
        
        # ä¹Ÿä¿å­˜ä¸º OBJ æ ¼å¼ï¼ˆå…¼å®¹æ€§ï¼‰
        obj_path = output_dir / f"{output_name}.obj"
        outputs[0].export(str(obj_path))
        logging.info(f"  - OBJ æ ¼å¼: {obj_path}")
        
        # è¾“å‡ºç»Ÿè®¡ä¿¡æ¯
        mesh = outputs[0]
        logging.info("\n" + "="*60)
        logging.info("âœ… ç»†åŒ–å®Œæˆï¼")
        logging.info(f"  - é¡¶ç‚¹æ•°: {len(mesh.vertices):,}")
        logging.info(f"  - é¢æ•°: {len(mesh.faces):,}")
        logging.info(f"  - è¾“å‡ºè·¯å¾„: {output_path}")
        logging.info("="*60 + "\n")
        
        # æ¸…ç†æ˜¾å­˜
        gc.collect()
        torch.cuda.empty_cache()
        
        return str(output_path)
        
    except Exception as e:
        logging.error(f"âœ— ç»†åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def main():
    parser = argparse.ArgumentParser(
        description="UltraShape é€šç”¨ç»†åŒ–æ¨¡å— - æ”¯æŒæ‰€æœ‰ 3D é‡å»ºæ¨¡å‹",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # ç»†åŒ– InstantMesh è¾“å‡º
  python run_ultrashape.py --image test.png --mesh outputs/instantmesh/latest.obj
  
  # ç»†åŒ– TRELLIS.2 è¾“å‡ºï¼ˆé«˜è´¨é‡ï¼‰
  python run_ultrashape.py --image test.png --mesh outputs/trellis2/mesh.glb --preset high
  
  # ç»†åŒ– Hunyuan3D è¾“å‡ºï¼ˆå¿«é€Ÿé¢„è§ˆï¼‰
  python run_ultrashape.py --image test.png --mesh outputs/hunyuan3d/mesh.glb --preset fast --low-vram
  
  # è‡ªå®šä¹‰å‚æ•°
  python run_ultrashape.py --image test.png --mesh mesh.glb --steps 100 --octree-res 2048
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument("--image", required=True, help="å‚è€ƒå›¾åƒè·¯å¾„")
    parser.add_argument("--mesh", required=True, help="è¾“å…¥ç½‘æ ¼è·¯å¾„ï¼ˆ.glb/.objï¼‰")
    
    # è¾“å‡ºé…ç½®
    parser.add_argument("--output", default="outputs/ultrashape", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--ckpt", default="checkpoints/ultrashape_v1.pt", help="æ¨¡å‹æƒé‡è·¯å¾„")
    parser.add_argument("--config", default="configs/infer_dit_refine.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    
    # è´¨é‡é¢„è®¾
    parser.add_argument(
        "--preset",
        choices=["lowmem", "fast", "balanced", "high", "ultra"],
        default="balanced",
        help="è´¨é‡é¢„è®¾ (lowmem: 6GBå³°å€¼, fast: 8GBå³°å€¼, balanced: 14GBå³°å€¼, high: 20GB, ultra: 32GB)"
    )
    
    # é«˜çº§å‚æ•°ï¼ˆè¦†ç›–é¢„è®¾ï¼‰
    parser.add_argument("--steps", type=int, help="æ¨ç†æ­¥æ•°ï¼ˆè¦†ç›–é¢„è®¾ï¼‰")
    parser.add_argument("--num-latents", type=int, help="æ½œåœ¨ token æ•°é‡ï¼ˆè¦†ç›–é¢„è®¾ï¼‰")
    parser.add_argument("--octree-res", type=int, help="Marching Cubes åˆ†è¾¨ç‡ï¼ˆè¦†ç›–é¢„è®¾ï¼‰")
    parser.add_argument("--chunk-size", type=int, help="æ‰¹å¤„ç†å—å¤§å°ï¼ˆè¦†ç›–é¢„è®¾ï¼‰")
    parser.add_argument("--guidance-scale", type=float, default=5.0, help="CFG å¼•å¯¼å¼ºåº¦")
    parser.add_argument("--scale", type=float, default=0.99, help="ç½‘æ ¼å½’ä¸€åŒ–æ¯”ä¾‹")
    parser.add_argument("--seed", type=int, default=42, help="éšæœºç§å­")
    
    # ä¼˜åŒ–é€‰é¡¹
    parser.add_argument("--low-vram", action="store_true", help="å¯ç”¨ä½æ˜¾å­˜æ¨¡å¼ï¼ˆCPU offloadingï¼‰")
    parser.add_argument("--remove-bg", action="store_true", help="è‡ªåŠ¨ç§»é™¤å›¾åƒèƒŒæ™¯")
    
    args = parser.parse_args()
    
    # æ˜¾ç¤ºé¢„è®¾ä¿¡æ¯
    if args.preset:
        preset_info = QUALITY_PRESETS.get(args.preset, {})
        print(f"\n{'='*60}")
        print(f"ğŸ¯ è´¨é‡é¢„è®¾: {args.preset.upper()}")
        print(f"   {preset_info.get('description', 'N/A')}")
        print(f"{'='*60}\n")
    
    # æ‰§è¡Œç»†åŒ–
    result = refine_mesh(
        image_path=args.image,
        mesh_path=args.mesh,
        output_dir=args.output,
        ckpt_path=args.ckpt,
        config_path=args.config,
        preset=args.preset,
        steps=args.steps,
        num_latents=args.num_latents,
        octree_res=args.octree_res,
        chunk_size=args.chunk_size,
        guidance_scale=args.guidance_scale,
        scale=args.scale,
        seed=args.seed,
        low_vram=args.low_vram,
        remove_bg=args.remove_bg
    )
    
    if result:
        print(f"\nğŸ‰ ç»†åŒ–æˆåŠŸï¼è¾“å‡º: {result}")
        return 0
    else:
        print("\nâŒ ç»†åŒ–å¤±è´¥")
        return 1


if __name__ == "__main__":
    sys.exit(main())
