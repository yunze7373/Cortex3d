这个项目主要是通过提示词，或者图片来通过AI生成3D模型，然后通过Blender进行模型的优化，最后导出STL文件。

AI生成3D模型的流程：
1. 通过提示词生成4张视图的图片
2. 通过图片生成3D模型
3. 通过3D模型生成STL文件

并且能够充分利用多视角的图片来生成高还原度的3D模型。
3d模型主要用来3d打印1/64的手办。

也就是使用gemini nanobanana pro来生成多个视图的图片，然后通过InstantMesh生成3D模型，最后通过Blender进行模型的优化，最后导出STL文件。

gemini nanobanana pro生成多视角图片已经通过提示词工程测试成功，能够生成比较理想的多视角图。可以通过项目里面的提示词来生成。

现在接下来我想测试一下。nanobanana pro来生成多个视图的图片来使用InstantMesh生成3D模型我想先完成这个步骤，将这个步骤进行技术测试。
整个项目的说明文档在项目文件夹里。你可以参考。

最终是实现和tripo3d一样的产品



第二部分要求：
另外请帮我直接生成一个可以gemini api的nanobanana模型的脚本，直接使用提示词来生成四个角度的2d模型图片。然后自动切割，生成到test_images/的完整脚本，我已经有gemini api的key了。
生成图片的脚本，应该可以做到，我描述人物，就能生成精准的四张多视角图像。
所以还需要你集成改造一下提示词模版，能够让程序的ai模块可以实现通过形容想要的模型样子，然后自动匹配生成多视角的图片。我文档里已经有相关的提示词了。


我在另外一个项目搭建了aiproxy服务。现在部署在ssh opc3上面，你可以检查aiproxy项目来看看它是如何直接通过我的代理服务器直接调用gemini的banana模型的。我项目的aiproxy服务的域名是bot.bigjj.click/generate,具体的还需要你帮我通过ssh opc3访问检测一下。
有了这个就可以添加一个直接使用aiproxy调用gemini nanobanana pro的接口。

1.首先，生成的图并不是前后左右四个视角的图像，只有前方视角图，和重复的两个左侧视角图。没有右侧视角图和后方视角图。
2.另外图的切割也没有根据图像对象来进行切割，而只是单纯对整个图进行四个等分切割。切出来的图都把对象完全分断了。
3.这个问题主要原因之一就是图片生成提示词没有要求对输出结果的图像布局与个数大小的严格控制。
其次切割脚本没有与提示词生成的原始图片进行匹配切割。


1.生成的视角的左侧视角和右侧视角的动作和前后视角的动作没有保持一致。一定要求每个视角的动作都是一致的。不要出现违背常理的情况，前后拿着斧子，但是左右却张开双手，一定要要求么哥视角的动作服装造型保持一致。
2.生成的图有时候是四个竖版图片，而不是田字框的排版，所以切割脚本还是需要进一步智能切割，能够自动识别排版线来进行切割。