# GPU 开发平台统一架构与使用指南

> **这是一个「远程可访问 · 本地算力在日本 · 项目级 GPU 隔离 · 可长期扩展」的 GPU 加速开发与运行平台。**

---

## 快速连接

```bash
# Mac 连接 WSL
ssh han-wsl

# 进入项目
cd ~/projects/<项目名>

# 进入容器
docker compose exec <服务名> bash
```

---

## 一、系统架构

```
[客户端] Mac / iPhone
    ↓ SSH + ZeroTier (192.168.192.125)
[接入层] Windows 11 (NVIDIA Driver + OpenSSH)
    ↓ wsl -d Ubuntu
[运行层] WSL2 Ubuntu (Docker + NVIDIA Container Toolkit)
    ↓
[项目层] Docker Containers (每项目独立 compose, GPU 直通)
```

**核心原则：**
- Windows = 门面 + 驱动（不跑项目）
- WSL = 项目管理（不 pip install）
- Docker = 项目运行环境（完全隔离）

---

## 二、目录规范

```
~/projects/
├─ cortex3d/          # 3D 模型生成
├─ llm-api/           # LLM 推理
├─ train-xxx/         # 训练项目
└─ templates/gpu-base # GPU 模板

~/data/
├─ datasets/          # 共享数据集
├─ models/            # 模型权重
└─ outputs/           # 输出结果
```

---

## 三、新建 GPU 项目标准流程

### Step 1: 创建 Dockerfile

```dockerfile
FROM nvidia/cuda:12.1.1-cudnn8-devel-ubuntu22.04

ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
# 根据 GPU 设置架构 (RTX 3080 Ti = 8.6, RTX 4090 = 8.9)
ENV TORCH_CUDA_ARCH_LIST="8.6"

# 基础依赖
RUN apt-get update && apt-get install -y \
    python3 python3-pip python3-dev git \
    libgl1-mesa-glx libglib2.0-0 \
    ninja-build g++ \
    && rm -rf /var/lib/apt/lists/*

# PyTorch (根据 CUDA 版本选择)
RUN pip3 install --no-cache-dir \
    torch torchvision \
    --index-url https://download.pytorch.org/whl/cu121

# 项目依赖 (根据需要添加)
# RUN pip3 install --no-cache-dir ...

# ⚠️ 需要编译的包 (如 nvdiffrast) 必须加验证
# RUN pip3 install --no-cache-dir --no-build-isolation \
#     git+https://github.com/xxx/xxx/ \
#     && python3 -c "import xxx; print('✅ xxx OK')"

WORKDIR /workspace

# 最终验证 (构建时确认依赖正确)
RUN python3 -c "import torch; print(f'✅ PyTorch {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
```

### Step 2: 创建 compose.yml

```yaml
services:
  dev:
    build:
      context: .
      dockerfile: Dockerfile
    image: <项目名>:latest
    container_name: <项目名>-dev
    working_dir: /workspace
    volumes:
      - ./:/workspace
      - hf-cache:/root/.cache/huggingface
      - ~/data:/data
    shm_size: "8gb"
    stdin_open: true
    tty: true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  hf-cache:
```

### Step 3: 构建并运行

```bash
# 首次构建
docker compose build

# 启动
docker compose up -d

# 进入容器
docker compose exec dev bash

# 验证 GPU
python3 -c "import torch; print(torch.cuda.get_device_name(0))"
```

---

## 四、常见问题与解决方案

### ❌ ModuleNotFoundError: No module named 'xxx'

**原因：** 依赖没写进 Dockerfile，或构建时静默失败

**解决：**
1. 确保依赖在 Dockerfile 中
2. 添加安装后验证步骤
3. 重新构建 `docker compose build --no-cache`

```dockerfile
# 正确写法：安装 + 验证
RUN pip3 install xxx \
    && python3 -c "import xxx; print('✅ xxx installed')"
```

### ❌ nvdiffrast / PyTorch3D 编译失败

**原因：** 需要 CUDA 架构信息，但 Docker 构建时没有 GPU

**解决：** 设置 `TORCH_CUDA_ARCH_LIST` 环境变量

```dockerfile
# RTX 3080 Ti
ENV TORCH_CUDA_ARCH_LIST="8.6"

# RTX 4090
ENV TORCH_CUDA_ARCH_LIST="8.9"

# 多 GPU 兼容
ENV TORCH_CUDA_ARCH_LIST="8.0;8.6;8.9"
```

### ❌ 容器重建后依赖丢失

**原因：** 手动在容器里 pip install，没写进 Dockerfile

**解决：** 
- ⚠️ **永远不要**在容器里手动 pip install 后就认为"装好了"
- 所有依赖必须写进 Dockerfile，然后 `docker compose build`

### ❌ SSH 连接断开后任务中断

**解决：** 使用 tmux

```bash
# 创建会话
tmux new -s train

# 断线后恢复
tmux attach -t train
```

---

## 五、远程连接方式

### macOS

```bash
ssh han-wsl
cd ~/projects/<项目名>
docker compose exec dev bash
```

### iPhone (Termius)

- Host: `192.168.192.125`
- User: `han`
- Key: SSH 私钥

---

## 六、多项目管理规则

| 规则 | 目的 |
|------|------|
| 每项目一个 compose.yml | 避免端口/依赖冲突 |
| 每项目独立镜像名 | 防止误用 |
| 公共数据走 `~/data` | 不重复下载 |
| 不共用 Python 环境 | 彻底隔离 |

---

## 七、GPU 架构速查表

| GPU | 架构 | TORCH_CUDA_ARCH_LIST |
|-----|------|----------------------|
| RTX 3060/3070/3080/3090 | Ampere | 8.6 |
| RTX 3080 Ti | Ampere | 8.6 |
| RTX 4060/4070/4080/4090 | Ada Lovelace | 8.9 |
| A100 | Ampere | 8.0 |
| H100 | Hopper | 9.0 |

---

## 八、核心思想

> **GPU 是稀缺资源，Docker 是隔离边界，WSL 是稳定底座，Windows 只是入口。**

- ✅ 所有依赖写进 Dockerfile
- ✅ 安装后立即验证
- ✅ 使用 `--no-cache` 排查问题
- ✅ tmux 保护长时间任务

---

## 九、案例复盘：InstantMesh 部署实战

在 Docker 中部署复杂 ML 项目（如 InstantMesh）时的典型问题与解决方案。

### 1. nvdiffrast 安装 "幽灵" 问题

**现象：** Dockerfile 中已经 `RUN pip install` 成功，且有缓存，但后续步骤或运行时报 `ModuleNotFoundError`。或 `pip list` 显示包名为 `UNKNOWN`。

**原因：**
1. **安装顺序问题**：如果在安装 nvdiffrast 后又运行了大量的 `pip install`（涉及卸载/更新依赖），可能破坏了 nvdiffrast 的环境。
2. **构建工具过旧**：旧版 `pip` / `setuptools` 对某些复杂的 `setup.py` 支持不佳，导致安装元数据丢失（显示为 UNKNOWN）。
3. **Editable Install**：在 Docker 中使用 `pip install -e .` 是反模式，因为源码目录在构建时可能会变动，且部署时应使用静态安装。

**解决方案：**
- **移至最后**：将容易出错的编译型库（nvdiffrast/pytorch3d）移到 Dockerfile 的**最后一步**安装。
- **升级工具**：`RUN pip3 install --upgrade pip setuptools wheel`。
- **放弃 Editable**：使用 `pip3 install .` 而非 `-e .`。
- **验证**：不依赖 `pip list`（grepping UNKNOWN 会失败），直接用 `python3 -c "import nvdiffrast.torch"` 验证。

### 2. Dependency Hell (依赖地狱)

**现象：**
- `ImportError: huggingface-hub>=0.16.4,<1.0 is required...`
- `ERROR: Cannot install ... because these package versions have conflicting dependencies.`

**原因：**
- `transformers 4.34` 锁死了 `huggingface-hub < 1.0`。
- `diffusers 0.20` 需要 `huggingface-hub >= 0.13`。
- `pip` 默认行为是激进升级，如果分多行写 `RUN pip install ...`，后面的包可能会把前面的包依赖偷偷升级到不兼容的新版（如升级到 1.x）。

**解决方案：**
- **合并命令**：将所有相关 ML 包写在**同一行** `RUN pip install a b c ...`，强制 pip 解决全局依赖冲突。
- **手动钉死关键包**：
    ```dockerfile
    # 黄金组合 (兼容 Transformers 4.34 + Diffusers 0.20)
    RUN pip3 install \
        transformers==4.34.1 \
        diffusers==0.20.2 \
        huggingface-hub==0.16.4 \
        accelerate==0.24.1 \
        pytorch-lightning==2.1.2
    ```

### 3. HuggingFace 相对路径报错

**现象：** `HFValidationError: Repo id must use alphanumeric chars... './zero123plus'`

**原因：**
- HuggingFace 库（diffusers/huggingface_hub）认为以 `./` 开头的字符串是无效的 Repo ID。
- 虽然代码意图是指向本地文件夹，但新版库对此校验更严格，或者需要绝对路径。

**解决方案：**
- **使用绝对路径**：
    ```python
    import os
    script_dir = os.path.dirname(os.path.abspath(__file__))
    pipeline_path = os.path.join(script_dir, "zero123plus")
    # ... custom_pipeline=pipeline_path ...
    ```
- **绕过子模块**：如果修改的是 submodule 代码且无法 push，可创建本地 wrapper 脚本（如 `scripts/run_instantmesh.py`）来覆盖原有逻辑。
